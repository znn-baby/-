# 总结

## java

### 面向对象

可维护 可扩展 可复用 灵活性好

**继承**

继承中,
属性：不可被重写,只会被隐藏
方法：会被重写,不会隐藏

**即：**
多态中，**成员变量**：
无论编译和运行，都参考左边(引用型变量所属的类)。

**也就是说
Fu f = new Zi();
System.out.println(f.age);
打印的还是父类的值。**

### ArrayList

#### 循环遍历并删除元素的常见陷阱

[原文链接](https://www.cnblogs.com/huangjinyong/p/9455163.html)

在工作和学习中，经常碰到删除ArrayList里面的某个元素，看似一个很简单的问题，却很容易出bug。不妨把这个问题当做一道面试题目，我想一定能难道不少的人。今天就给大家说一下在ArrayList循环遍历并删除元素的问题。首先请看下面的例子：

```
import java.util.ArrayList;
public class ArrayListRemove
{
　　publicstaticvoidmain(String[]args)
　　{
　　　　ArrayList<String>list=newArrayList<String>();
　　　　list.add("a");
　　　　list.add("b");
　　　　list.add("b");
　　　　list.add("c");
　　　　list.add("c");
　　　　list.add("c");
　　　　remove(list);
　　　　for(Strings:list)
　　　　{
　　　　　　System.out.println("element : "+s);
　　　　}
　　}
　　public static void remove(ArrayList<String> list)
　　{
　　// TODO:
　　}
}
```

如果要想删除list的b字符，有下面两种常见的错误例子：

错误写法实例一：

```
public static void remove(ArrayList<String> list)
{
    for(inti=0;i<list.size();i++)
    {
        Strings=list.get(i);
        if(s.equals("b"))
        {
            list.remove(s);
        }
    }
}
```



错误的原因：这种最普通的循环写法执行后会发现第二个“b”的字符串没有删掉。

错误写法实例二：



```
public static void remove(ArrayList<String> list)
{
    for(Strings:list)
    {
        if(s.equals("b"))
        {
            list.remove(s);
        }
    }
}
```



错误的原因：这种for-each写法会报出著名的并发修改异常：java.util.ConcurrentModificationException。

先解释一下实例一的错误原因。翻开JDK的ArrayList源码，先看下ArrayList中的remove方法（注意ArrayList中的remove有两个同名方法，只是入参不同，这里看的是入参为Object的remove方法）是怎么实现的：



```
public boolean remove(Objecto){
    if(o==null){
        for(intindex=0;index<size;index++)
            if(elementData[index]==null){
                fastRemove(index);
                return true;
            }
            }else{
                for(intindex=0;index<size;index++)
                if(o.equals(elementData[index])){
                fastRemove(index);
                return true;
            }
    }
    return false;
}            
```



一般情况下程序的执行路径会走到else路径下最终调用faseRemove方法：



```
private void fastRemove(int index){
        modCount++;
        intnumMoved=size-index-1;
        if(numMoved>0)             
        　　System.arraycopy(elementData,index+1,elementData,index,numMoved);
        elementData[--size]=null;// Let gc do its work
}
```



可以看到会执行System.arraycopy方法，导致删除元素时涉及到数组元素的移动。针对错误写法一，在遍历第一个字符串b时因为符合删除条件，所以将该元素从数组中删除，并且将后一个元素移动（也就是第二个字符串b）至当前位置，导致下一次循环遍历时后一个字符串b并没有遍历到，所以无法删除。针对这种情况可以倒序删除的方式来避免：



```
public static void remove(ArrayList<String> list)
{
    for(inti=list.size()-1;i>=0;i--)
    {
        Strings=list.get(i);
        if(s.equals("b"))
        {
            list.remove(s);
        }
    }
}
```



因为数组倒序遍历时即使发生元素删除也不影响后序元素遍历。

接着解释一下实例二的错误原因。错误二产生的原因却是foreach写法是对实际的Iterable、hasNext、next方法的简写，问题同样处在上文的fastRemove方法中，可以看到第一行把modCount变量的值加一，但在ArrayList返回的迭代器（该代码在其父类AbstractList中）：

```
public Iterator<E> iterator() {
        return new Itr();
}
```

这里返回的是AbstractList类内部的迭代器实现private class Itr implements Iterator，看这个类的next方法：



```
public E next() {
        checkForComodification();
        try {
            E next = get(cursor);
            lastRet = cursor++;
            return next;
        } catch (IndexOutOfBoundsException e) {
            checkForComodification();
            throw new NoSuchElementException();
        }
}
```



第一行checkForComodification方法：

```
final void checkForComodification() {
        if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
}
```

这里会做迭代器内部修改次数检查，因为上面的remove(Object)方法修改了modCount的值，所以才会报出并发修改异常。要避免这种情况的出现则在使用迭代器迭代时（显示或for-each的隐式）不要使用ArrayList的remove，改为用Iterator的remove即可。



```
public static void remove(ArrayList<String> list) 
    {
        Iterator<String> it = list.iterator();
        while (it.hasNext()) 
        {
            String s = it.next();
            if (s.equals("b")) 
            {
                it.remove();
            }
        }
}
```



### hashCode和equals

**为什么重写了equals就需要重写hashCode**

这是一条规范，如果不这样做会隐藏bug。

一个类的对象如果会存储在HashTable,HashSet,HashMap等散列存储结构中，那么重写equals后最好也重写hashCode，否则会导致存储数据的不唯一行（存储两个equals相等的数据）。如果确定不会存储在这些散列结构中，则可以不重写hashCode。但是谁能保证后期不会存储在这些结构中呢，况且重写了hashCode也不会降低性能，线性结构（如ArrayList）中不会掉用hashCode，所以重写了也不要紧，也为后期的修改打了补丁。

![对象放入散列集合的流程图](./总结的图片/对象放入散列集合的流程图.gif)

在存储一个对象时，先进行hashCode值的比较，然后进行equals的比较。

**内存泄漏问题：**

如set中已经存在两个对象p1被分配到1号桶中，p2被分配到了2号桶中，然后修改了p2中与计算hashCode有关的信息x（比如hashCode由常数*成员变量x得出）当调用remove（Object obj）时，先查找该hashCode值的对象是否在集合中，假设修改后的hashCode值为10（仍存在2号桶中），这时查找结果为空，jdk认为该对象不在集合中，所以不会进行删除操作。然而用户以为该对象已经被删除，导致该对象长时间不能被释放，造成内存泄漏。

解决该问题的办法是不要在执行期间修改与hashCode值有关的对象信息，如果非要修改，则必须先从集合中删除，更新信息后再加入集合中。



### hashMap

当键值为对象类型的时候，放在hashMap key上的元素要需重写equals方法和hashCode方法

 因为hashMap的集合key会先后调用两个方法 hashCode和equals，hashCode来确定在数组上的位置，equals来判断是否有重复的key，equals方法默认比较的是两个对象的地址。

如果只重写hashCode方法 两个不同对象 但是值相同的对象的存储地址一样，但是equals方法比较的是对象地址，所以这两个对象都会存入hashMap

如果只重写equals方法，值相同的两个对象会存入不同map的地址

#### 不安全原因

**jdk1.7**：扩容时需要将原来的数据转移到newTable中，转移元素时使用的是头插法，链表的顺序会翻转，这里是形成死循环的关键点。



### 锁

#### lock和synchronized



#### 可重入锁、不可重入锁、公平锁、不公平锁、读写锁



#### 锁升级 无锁、偏向锁、轻量级锁（自旋锁）、重量级锁

锁状态只能升级不能降级

**偏向锁**：执行到synchronized代码块的时候，锁对象变成偏向锁（会在Mark Word里存储锁偏向的线程ID），执行完同步代码块后，线程不主动释放偏向锁，第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也不需要重新加锁。如果自始至终使用锁的线程只有一个，偏向锁几乎没有额外开销，性能极高。适用于只有一个线程访问同步块场景。当有锁竞争（如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁一觉被占用，只能等待其释放，这才发生了锁竞争。）时，升级为轻量级锁。

关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于，则将对象头设置为无锁状态，并撤销偏向锁，恢复到无锁或轻量级锁的状态。

**轻量级锁**：线程在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停的循环判断是否能够获取锁。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。竞争的线程不会阻塞，提高了程序的响应速度，但是如果一个线程持有锁，其他线程只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waitting）。如果多个线程用一个锁，但是没有发生锁竞争，或者发生了很轻微的锁竞争，那么synchronized就用轻量级锁，允许段时间的忙等现象。这是一种折中的想法，段时间的忙等，换取线程在用户态和内核态之间切换的开销。有计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改。自旋十次失败升级为重量级锁。

重量级锁：如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁（依然是CAS修改锁标志位，但不修改持有锁的线程ID）。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起而不是忙等，等待将来被唤醒。

重量级锁是指当有一个线程获取锁之后，其余线程都会处于阻塞状态。

简言之，就是将所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资源。

线程竞争不使用自旋，不会消耗CPU，线程阻塞，响应时间缓慢

#### 分布式锁



### Thread

#### interrupt

-- interrupt方法干了什么？

interrupt方法其实只是改变了中断状态而已。

而sleep、wait和join这些方法的内部会不断的检查中断状态的值，从而自己抛出InterruptedException。

所以，如果在线程进行其他处理时，调用了它的interrupt方法，线程也不会抛出InterruptedException的，只有当线程走到了sleep, wait, join这些方法的时候，才会抛出InterruptedException。若是没有调用sleep, wait, join这些方法，或者没有在线程里自己检查中断状态，自己抛出InterruptedException，那InterruptedException是不会抛出来的。

 

isInterrupted方法，可以用来检查中断状态

Thread.interrupted方法，可以用来检查并清除中断状态

原文链接：https://blog.csdn.net/derekjiang/article/details/4845757

关于这三个方法，interrupt（）是给线程设置中断标志；interrupted（）是检测中断并清除中断状态；isInterrupted（）只检测中断。还有重要的一点就是**interrupted（）作用于当前线程**，interrupt（）和isInterrupted（）作用于此线程，即代码中调用此方法的实例所代表的线程。
原文链接：https://blog.csdn.net/qq_39682377/article/details/81449451

#### wait和sleep

wait释放锁，待调用notify()/notifyAll()唤醒指定的线程或所有线程，才会进入锁池，只能在同步代码块或同步方法中执行，是Object的方法

sleep不释放锁，可以在任何地方使用，是线程类（Thread）的方法



### BIO

#### 监听端口，与之通讯

例子功能：监听6666端口当有客户端连接时，启动一个线程与之通讯

例子名称：znnNioTest

监听端口并读取数据流程

1.创建一个线程池（用来与端口通讯，可以有多个客户端）

2.创建serverSocket

```java
ServerSocket serverSocket = new ServerSocket(6666);
```

3.在循环中等待客户端连接,accept是阻塞的，当有连接时才会继续执行后续操作

```java
final Socket socket = serverSocket.accept();
```

4.连接到客户端后 创建一个线程与之通讯

  通讯：	

​	1.通过socket获取输入流 获取一次输入流即可

```java
InputStream inputStream = socket.getInputStream();
```

​	2.循环读取数据 read方法是阻塞的

```java
int read = inputStream.read(bytes);
```

​	3.输出客户端发送的数据

#### 获取输入流socket.getinputstream

1.获取一次就可以，然后从inputstream中不停的循环读取就好了，read方法是阻塞式的，没有数据的时候会阻塞在那里，等有数据来了就会再次执行。

2.只要socket没有手动关闭或异常关闭的情况下，里面的输入流和输出流都只用取一次就可以循环的执行读写操作，读写操作完成不要关闭流，关闭的话socket就失效了，需要重新建立socket链接



### NIO

#### 三大核心 Channel(通道)，Buffer(缓冲区), Selector(选择器) 

​											--buffer(服务端buffer) -- channel -- buffer(客户端buffer) -- 客户端

​	server服务端-selector  --buffer(服务端buffer) -- channel -- buffer(客户端buffer) -- 客户端

​											--buffer(服务端buffer) -- channel -- buffer(客户端buffer) -- 客户端



### JVM

#### JVM内存分代模型（用于垃圾回收算法）

1.部分垃圾回收器使用的模型

2.

#### JVM调优

如何查看JVM系统参数的默认值

```shell
java -XX:+PrintFlagsInitial --查看出厂默认值``java -XX:+PrintFlagsFinal --查看修改更新 (= 没有修改过 := 人为修改过)``java -XX:+PrintFlagsFinal -XX:MetaspaceSize=512m  查看系统参数，并修改元空间大小 
```

 

```shell
java -XX:+PrintCommandLineFlags -version --打印命令行参数(可以看默认垃圾回收器)　
```

### cpu

#### cache

L1、L2、L3缓存  由 ICache 和 DCache 构成L1 Cache



### RMI

**Java RMI**，即 **远程方法调用**([Remote Method Invocation](https://links.jianshu.com/go?to=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDistributed_object_communication))一种用于实现**远程过程调用**(RPC)[(Remote procedure call)](https://links.jianshu.com/go?to=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FRemote_procedure_call)的Java API， 能直接传输序列化后的Java对象和[分布式垃圾收集](https://links.jianshu.com/go?to=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDistributed_Garbage_Collection)。它的实现依赖于[Java虚拟机](https://links.jianshu.com/go?to=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FJava_Virtual_Machine)(JVM)，因此它仅支持从一个JVM到另一个JVM的调用。



### Request

经常使用request.getContextPath()，但对它的具体作用有时还是不太明白。其实它的作用是获取当前的系统路径。

比如，如果使用Tomcat作为服务器部署项目，一般将项目部署到webapps下（当然，也有可能是wtpwebapps，详细可见我的另一篇《Tomcat6中web项目部署路径webapps和wtpwebapps的区别》）。这时有两种情况：

如果将项目WebRoot中的内容直接拷贝到webapps中的ROOT下，则request.getContextPath()的值为空，注意是”“，而不是null。

如果不将项目放在ROOT中，而是在webapps下新创建一个文件夹，例如命名为“Proj”，然后将项目WebRoot中的内容拷贝到这个“Proj”文件夹下，则request.getContextPath()的值为该新建文件夹的名称，这里也就是“Proj”。
————————————————
版权声明：本文为CSDN博主「我是干勾鱼」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/dongdong9223/article/details/48998099

**request.getServletPath()，request.getContextPath()的总结**

getServletPath():获取能够与“url-pattern”中匹配的路径，注意是完全匹配的部分，*的部分不包括。
getPathInfo():与getServletPath()获取的路径互补，能够得到的是“url-pattern”中*d的路径部分
getContextPath():获取项目的根路径
getRequestURI:获取根路径到地址结尾
getRequestURL:获取请求的地址链接（浏览器中输入的地址）
getServletContext().getRealPath("/"):获取“/”在机器中的实际地址
getScheme():获取的是使用的协议(http 或https)
getProtocol():获取的是协议的名称(HTTP/1.11)
getServerName():获取的是域名(xxx.com)
getLocalName:获取到的是IP
————————————————
版权声明：本文为CSDN博主「jwnba24」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_27770257/article/details/79438987



### URLEncoder.encode

我们先看2个编码的情况

```java
      String name=java.net.URLEncoder.encode("测试", "UTF-8");
      System.out.println(name);
      name=java.net.URLEncoder.encode(name,"UTF-8");
      System.out.println(name);
      name=java.net.URLDecoder.decode(name, "UTF-8");
      System.out.println(name);
      System.out.println(java.net.URLDecoder.decode(name, "UTF-8"));
```

输出结果是

 ```java
 			%E6%B5%8B%E8%AF%95
       %25E6%25B5%258B%25E8%25AF%2595
       %E6%B5%8B%E8%AF%95
       测试
 ```

1. 把“测试”编码一次的字符串%E6%B5%8B%E8%AF%95  ，提交给服务器，服务器端用request.getParameter("name")得到参数，然后我们解码System.out.println(java.net.URLDecoder.decode(name, "UTF-8"));

   得到的结果**???è?** 乱码。

   因为在request.getParameter("name")之前会自动做一次解码的工作，而且是默认的ISO-8859-1，相当于调用了一次java.net.URLDecoder.decode(name, "ISO-8859-1")

2. 编码2次的字符串是%25E6%25B5%258B%25E8%25AF%2595 ，编码两次，提交给服务器，服务器端用request.getParameter("name")的到参数，自动按ISO-8859-1解码得到的串是%E6%B5%8B%E8%AF%95  ，也就是编码一次得到的字符串

   然后，我们在System.out.println(java.net.URLDecoder.decode(name, "UTF-8"));解码输出，得到的结果就是 “测试” 2个汉字。



## 网络

### HTTP协议、socket接口

首先一定要明白：

HTTP协议：简单对象访问协议，对应于应用层 ，HTTP协议是基于TCP连接的 

TCP协议： 对应于传输层 

IP协议： 对应于网络层 TCP/IP是传输层协议，主要解决数据如何在网络中传输；而HTTP是应用层协议，主要解决如何包装数据。

 Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。

==看原文！写的很好==

原文链接：https://blog.csdn.net/cqx13763055264/article/details/79145928

### HTTPS

HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次**握手**，在握 手过程中将确立双方加密传输数据的密码信息，通常情况下会配合数字证书实现。

TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用 非对称加密，对称加密以及HASH算法。（加密内容详见本文档 加密解密---类型）

#### 握手过程

1. 浏览器将自己支持的一套加密规则发送给网站，如RSA加密算法，DES对称加密算法，SHA1摘要算法
2. 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密，在握手的整个过程中，都用到了证书中的公钥和浏览器发送给服务器的随机密码以及对称加密算法）
3. 获得网站证书之后浏览器要做以下工作：
     a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。
     b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
     c) 使用约定好的HASH算法计算握手消息（如SHA1)，并使用生成的随机数对消息进行加密，最后将之前生成的被公钥加密的<span style="color:red;">随机数密码，HASH摘要值一起发送给服务器</span>
4. 网站接收浏览器发来的数据之后要做以下的操作：
     a) 使用自己的私钥将信息解密并取出浏览器发送给服务器的随机密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
     b) 使用随机密码加密一段握手消息，发送给浏览器。
     5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。

==还未跟着例子练习==

[原文写的很好](https://www.cnblogs.com/gyadmin/p/8078781.html)

### FTP中ASCII和二进制传输模式的区别

FTP可用多种格式传输文件，通常由系统决定，大多数Linux/UNIX系统只有两种模式：文本模式和[二进制](https://so.csdn.net/so/search?q=二进制&spm=1001.2101.3001.7020)模式。文本传输器使用ASCII字符，并由回车键和换行符分开，而二进制不用转换或格式化就可传字符，**二进制模式比文本模式更快，并且可以传输所有ASCII值**，所以系统管理员一般将FTP设置成二进制模式。 
一般来说： 如果你用错误的模式传输你的图片，你将可能无法看到图片，看到的会是乱码。 如果你用错误模式上传CGI脚本，那么就将无法运行你的脚本，会看到类似Server 500 Error的出错信息。 
所以你必须使用正确的模式，图片和执行文件必须用BINARY模式，CGI脚本和普通HTML文件用ASCII模式上传。

ASCII和BINARY模式区别：

用HTML和文本编写的文件要用ASCII模式上传，用二进制模式上传会破坏文件，导致文件执行出错。 
BINARY模式用来传送可执行文件，压缩文件和图片文件。 
如果你用ASCII模式传，可能会显示一堆乱码，你必须重新用BINARY模式传。 
对于第二种情况，是因为有很多ftp服务器和FTP软件能自动识别文件类型，并采取相应的传输方式。 
FTP是应用层协议，和具体操作系统无关。

ASCII模式和BINARY模式的区别是回车换行的处理，binary模式不对数据进行任何处理，ASCII模式将回车换行转换为本机的回车字符，比如Unix下是\n,Windows下是\r\n，Mac下是\r 
ascii模式下会转换文件 
不能说是不同系统对回车换行解释不同 
而是不同的系统有不同的行结束符 
unix系统下行结束符是一个字节，即十六进制的0A 
而ms的系统是两个字节，即十六进制的0D0A

所以当你用ascii方式从unix的ftp server下载文件时(不管是二进制或者文本文件)，每检测到一个字节是0A，就会自动插入一个0D，所以如果你的文件是二进制文件比如可执行文件、压缩包什么的，就肯定不能用了。如果你的文件就是unix下的文本文件，你用 ascii模式是正确的，要是误用了binary模式，你在windows上看这个文件是没有换行的，里面是一个个的黑方块。

**一般来说，我们最好都用binary方式，这样可以保证不出错。如果有文本格式转换的问题，即unix格式的文本和dos格式的文本之间的转换，有很多工具可以做的，不要在ftp传输的时候冒险，尤其是你如果对这些东西不是非常清楚的话。** 
可以使用MIME，把所有的字符，转换成0~128之间的字符，然后传送，在接受方再将接收到的字符MIME反向转换。通常我们发送邮件，就是使用这样的字符转换方式 
补充：文本模式和二进制模式传文本文件的具体区别可以通过在linux下使用cat -A 文件名看到两者的区别，当然前提是在windows下上传的文本为dos格式，这个可以用高级的文本编辑器看如ultraedit等。两者的区别是二进制模式上传的文本比文本模式多一个^M符号，这个就是windows下dos格式的/r回车符号，也就是上面提到的十六进制的0D，在vi下使用全局替换:%s/^M//g[^M使用Ctrl+V+M而不是直接输入^M]去掉所有的回车符或者使用dos2unix file进行转换，这样保存后或者生成后的文件就和文本模式上传的文件一样了。



### IOS8583报文

有规定的128个字段，设置了数据类型和长度、

报文前有包头，16个字节即128bit，来表示128个字段中的某个字段是否存在，如果是1表示对应的字段在本次报文中存在，这16个字节称为 bit map 位图，考虑到很多时候不需要128个字段，所以将报文头缩短到64bit，只有在需要的时候将剩下的64bit放到报文里。

<img src="typora图片/8583位图介绍.png" alt="image-20220221100735000" style="zoom:50%;" />

对于字段长度如果大于规定长度怎么办，如账号是不定长的，如果超过规定长度怎么办，字段也不能设置很大，否则如果字段很短，如定为100位，只有19位的账号，那剩下的81位的数据就浪费网络带宽，所以在变长的字段前面加上字段长度：

<img src="typora图片/image-20220221101731676.png" alt="image-20220221101731676" style="zoom:50%;" />



## 输入输出流

### 输入输出流操作同一个文件的问题及解决办法

**1.问题场景**

复制目标excel中第一个sheet模版 填充数据 并放到当前excel最后

**2.代码规划**

规划使用FileInputStream读取，WorkbookFactory.create()得到excel内容，编辑后FileOutputStream写入原文件

``` java
/**
 * 复制excel中的第一个sheet 复制到当前excel中
 */
@Override
public String copySheetInOneExcel(){
    String fromPath = "E:\\testExcel\\newExcel\\znn周报.xls";// excel模版
    Workbook wb;
    FileInputStream fis = null;
    FileOutputStream fos = null;
    try {
        fis = new FileInputStream(fromPath); //(1)
        fos = new FileOutputStream(fromPath); //(2)
        wb = WorkbookFactory.create(fis); //(3)
        wb.cloneSheet(0);
        wb.setSheetName(wb.getNumberOfSheets()-1,"0917");
        wb.write(fos);
        fis.close();
        fos.close();
        return "成功";
    } catch (Exception e) {
        e.printStackTrace();
        return "失败";
    } finally {
        try {
            if (fis != null)
                fis.close();
            if (fos != null)
                fos.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

**3.问题现象**
后台报错

<span style="color:red">org.apache.poi.poifs.filesystem.NotOLE2FileException: Invalid header signature;  read 0x0000000000000000, expected 0xE11AB1A1E011CFD0</span>

**4.分析推测**

发现程序报错后 访问的文件变成0kb，双击打开提示**文件格式和文件扩展名不匹配，文件已经损坏或不安全**点击确定，打开的是个空文件

打断点发现程序在第(3)步报错，但是走完第(2)步后 文件已经变成0kb

通过分析推测，输入流未关闭的情况下，输出流操作同一路径文件，会造成冲突，输入流会认为该文件不存在并重新创建同名文件覆盖原文件，而后输入流实际读取的是一个空文件，那么输出流写入的内容也为空，最后造成文件内容置空的现象。

**5.错误纠正**

在输入流操作完该文件后，输出流再进行文件操作，代码纠正如下：

```java
/**
 * 复制excel中的第一个sheet 复制到当前excel中
 */
@Override
public String copySheetInOneExcel(){
    String fromPath = "E:\\testExcel\\newExcel\\znn周报.xls";// excel模版
    Workbook wb;
    FileInputStream fis = null;
    FileOutputStream fos = null;
    try {
        fis = new FileInputStream(fromPath);
        //fos = new FileOutputStream(fromPath); 
        wb = WorkbookFactory.create(fis);
        wb.cloneSheet(0);
        wb.setSheetName(wb.getNumberOfSheets()-1,"0917");
        fos = new FileOutputStream(fromPath); //纠正增加的代码
        wb.write(fos);
        fis.close();
        fos.close();
        return "成功";
    } catch (Exception e) {
        e.printStackTrace();
        return "失败";
    } finally {
        try {
            if (fis != null)
                fis.close();
            if (fos != null)
                fos.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

## Excel操作

### 利用POI操作Excel文件

**POI的HSSFWorkbook**

Apache POI提供了操作microsoft documnent的java API，本文主要介绍HSSFWorkbook如何操作Excel文档。

HSSF是Horrible SpreadSheet Format的简称，主要用来读取和写入Excel文档

**1.引入POI依赖**

```xml
 <dependency>
      <groupId>org.apache.poi</groupId>
      <artifactId>poi</artifactId>
      <version>4.0.1</version>
  </dependency>
```

**2.写数据到excel中**

<https://www.cnblogs.com/way-sunshine/p/11606157.html>



## 线程池

Executors.newCacheThreadPool()：可缓存线程池，先查看池中有没有以前建立的线程，如果有，就直接使用。如果没有，就建一个新的线程加入池中，缓存型池子通常用于执行一些生存期很短的异步型任务



 Executors.newFixedThreadPool(int n)：创建一个可重用固定个数的线程池，以共享的无界队列方式来运行这些线程。



 Executors.newScheduledThreadPool(int n)：创建一个定长线程池，支持定时及周期性任务执行



Executors.newSingleThreadExecutor()：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。



## 登陆

摘要、签名、编码、加密是不同的三个概念。
使用base64url是把JSON编码，其实只不过是先扁平化再用64个可读无冲突字符来表达，毫无加密效果。SHA256的摘要只是为JSON数据生成一个“指纹”，防止被篡改，属于完整性范畴，也无任何加密效果，摘要不等于签名，签名是用私钥加密摘要。所以Token本身并没有任何加密机制，它依赖于HTTPS的通道保密能力。不过应该可以自己为Token增加加密机制，这就带来了额外的开销。

### JWT加密

Json web token (JWT)

是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（[(RFC 7519](https://link.jianshu.com/?t=https://tools.ietf.org/html/rfc7519)).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。
链接：https://www.jianshu.com/p/576dbf44b2ae



## 加密解密、签名验签

### 类型

- 对称加密算法

对加密和解密使用相同密钥的加密算法。由于其速度，对称性加密通常在消息发送方需要加密大量数据时使用。

常用的对称加密有： 

**AES**、**DES**、**IDEA**、**RC2**、**RC4**、**SKIPJACK**算法等 。

- 非对称加密算法

非对称加密算法的保密性比较好，它消除了最终用户交换密钥的需要

但加密和解密花费时间长、速度慢，它不适合于对文件加密而只适用于对少量数据进行加密

**RSA**、**DH (Diffie-Hellman)**、**EL Gamal**	、**ECC** 

- HASH算法

常用的摘要算法包括**MD5**，**SHA1**，**SHA256**

消息摘要算法的特点：

① 无论输入的消息有多长，计算出来的消息摘要的长度总是固定的。
② 消息摘要看起来是“随机的”。这些比特看上去是胡乱的杂凑在一起的。
③ 一般地，只要输入的消息不同，对其进行摘要以后产生的摘要消息也必不相同；但相同的输入必会产生相同的输出。
④ 消息摘要函数是无陷门的单向函数，即只能进行正向的信息摘要，而无法从摘要中恢复出任何的消息，甚至根本就找不到任何与原信息相关的信息。
⑤ 好的摘要算法，无法找到两条消息，是它们的摘要相同。

**可以检验数据的完整性**

消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密，只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文。消息摘要算法不存在 密钥的管理与分发问题，适合于分布式网络相同上使用。由于其加密计算的工作量相当可观，所以以前的这种算法通常只用于数据量有限的情况下的加密，例如计算机的口令就是 用不可逆加密算法加密的。

### RSA

**步骤**

1.整理需要签名的参数拼接成字符串 

2.将字符串使用私钥生成签名字符串

3.对签名字符串进行URL编码 urlEncodeSign

4.在请求头参数中带上签名字符串 urlEncodeSign

```java
headers.add("sign", urlEncodeSign);
```



内部 不同的模块间通信可以不加密解密，签名验签    同外部系统交互需要加密解密、签名验签

**公钥加密，私钥解密；私钥签名，公钥验签。**

**加密、解密**：这个好理解。例如 A、B之间相互传东西，A拥有A的私钥、B的公钥；B拥有B的私钥、A的公钥；这样当A给B传信息的时候，用B的公钥加密，这样只有B才能解密，保证了信息的安全。同理，B给A传信息是一样的。

**签名、验签**：主要是完成不可抵赖的作用。例如，A用私钥签名，然后用签名结果和A的公钥，就可以验证信息肯定是A发送的，而不是其他人发送的。

第一种用法：公钥加密，私钥解密。---用于加解密
第二种用法：私钥签名，公钥验签。---用于签名

有点混乱，不要去硬记，总结一下:
你只要想：
既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；
既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。

同一种道理，我在换种说法：
私钥和公钥是一对，谁都可以加解密，只是谁加密谁解密是看情景来用的：
第一种情景是签名,使用私钥加密,公钥解密,用于让所有公钥所有者验证私钥所有者的身份并且用来防止私钥所有者发布的内容被篡改.但是不用来保证内容不被他人获得。
第二种情景是加密,用公钥加密,私钥解密,用于向公钥所有者发布信息,这个信息可能被他人篡改,但是无法被他人获得。

比如加密情景：
如果甲想给乙发一个安全的保密的数据,那么应该甲乙各自有一个私钥,甲先用乙的公钥加密这段数据,再用自己的私钥加密这段加密后的数据.最后再发给乙,这样确保了内容即不会被读取,也不会被篡改.  



### base64加密

Base64是一种二进制到文本的编码方式。如果要更具体一点的话，可以认为它是一种将 `byte`数组编码为字符串的方法，而且编码出的字符串只包含ASCII基础字符。

==Base64不是加密算法，其仅仅是一种编码方式，算法也是公开的，所以不能依赖它进行加密。==

#### 为什么叫Base64？

因为它是基于(Base)64个字符的一种编码方式。使用其编码后的文本只包含64个ASCII码字符（偶尔加一个填充字符`=`），如下所示：

Base64使用到的64个字符：

- `A-Z` 26个
- `a-z` 26个
- `0-9` 10个
- `+` 1个
- `/` 1个

**使用 Base64 进行编码，大致可以分为 4 步**：

1. 将原始数据每三个字节作为一组，每个字节是8个bit，所以一共是 24 个 bit
2. 将 24 个 bit 分为四组，每组 6 个 bit
3. 在每组前面加补 00，将其补全成四组8个bit
   到此步，原生数据的3个字节已经变成4个字节了，增大了将近`30%`
4. 根据Base64码表得到扩展后每个字节的对应符号（见ASCII表）

假如我们的原文为`Man`，那么下图演示了如何按照上面的步骤将其编码为Base64字符串



<img src="typora图片/v2-d5fdfb360a4b460ce23f80849526dcb2_1440w.jpg" alt="img" style="zoom:80%;" />

可以发现`Man`对应的Base64为`TWFu`.现在大家应该明白为什么只有64个字符了吧？因为算法将将8bit分割成6bit了，而6bit的取值范围为`0~63`。

#### Base64字符串末尾的`=`是什么

有时我们会在Base64字符末尾会看到`=`，有时1个，有时2个，这是为啥？

通过上面的我们知道了Base64编码过程是3个字符一组的进行，如果原文长度不是3的倍数怎么办呢？ 例如我们的原文为`Ma`，它不够3个，那么只能在编码后的字符串中补`=`了。缺一个字符补一个，缺两个补两个即可，所以有时候你会看见base64字符串结尾有1个或者2个`=`。

<img src="typora图片/v2-a2558d2f1406bda51aa95852693dd84e_1440w.jpg" alt="img" style="zoom:80%;" />



#### Base64 DataURI格式

有时你会发现web页面传给你的base64字符串前面有类似下面的东东。

```text
data:image/jpeg;base64,    /9j/4AA...
```

这是DataURI，大部分浏览器支持直接打开这类二进制数据，但是我们要格外注意，如果你只是想要真实的Base64内容就需要取`,`后边的内容

[原文写的很好](https://zhuanlan.zhihu.com/p/384238870)

#### +号丢失  url参数+号丢失 待整理和测试

问题1：.net url参数  Request.QueryString["signature"]获取到base64加密后的带+号的字符串， +号会被移除

解决方法：通过request.QueryString得到的参数是带有+号，所以直接取

Dictionary<string, string> dict = new Dictionary<string, string>();
foreach (var temp in this.Request.QueryString.ToString().Split('&'))
{
var item = temp.Split('=');
dict.Add(item[0], item[1]);
}

 var signature =dict["signature"];

 

问题2：得到的签名如下S，但是需要验证该签名，通过对比调用java的生成签名接口要么是Adecode 要么是B encode

 S： jmkYG6BhZ+MTybi0xFCfLuAl%2fjpVgwOYusxSOQpQuLI%3d (+号是decode 而/和=是encode)  将S Decode  %2f-->/  %3d--> = 但是+号会被移除

将S Enocde +--> %2B 但是/和=生成的code是小写 %2f和%3d 而需要对比的签名B是大写的 哎

 A: jmkYG6BhZ+MTybi0xFCfLuAl/jpVgwOYusxSOQpQuLI=

 B：jmkYG6BhZ%2BMTybi0xFCfLuAl%2FjpVgwOYusxSOQpQuLI%3D

 

最终解决方案是 将+号手动转成编码，再次decode成符号 就OK了 

 var signature = HttpUtility.UrlDecode(dict["signature"].Replace("+", "%2B"));

//生成timestamp

private static long GetTimeStamp(DateTime dateTime)
{
var baseTime = new DateTime(1970, 1, 1);
return (dateTime.Ticks - baseTime.Ticks) / 10000000 - 8 * 60 * 60;
}

转载于:https://www.cnblogs.com/Amity1006/p/6627309.html



前台防止base64加密后丢+问题：

encodeURIComponent(“接口调用失败，请联系管理员”);
1
后台防止base64加密后丢+问题：

BASE64Encoder base64en = new BASE64Encoder();
 String infos = new String(base64en.encode(info.getBytes("UTF-8"))).replace("\n","").replace("\r","").replace("+","%2B");
1
2
注意：一定要加上replace("+","%2B")，把+替换，这样前台用base64解密才不会乱码
前台解密方式：

var msg = this.$route.query.info;
msg = Base64.decode(msg)
1
2
参考文档：
https://blog.csdn.net/sl0007/article/details/7990978?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control

原文链接：https://blog.csdn.net/weixin_41698201/article/details/113761118

### SM3国密

BocDigests digest;

BocSymmetricCrypt crypt;

BocCoder coder;

Charset charset = Charset.forName("utf-8");

将应用系统的密码转为UTF-8格式的byte数组 -> 国密SM3哈希计算byte数组 

```java
return digest.BOC_Digest(digest.BOC_DigestInit(BocDigests.HASH_SM3), data);//data是应用系统的密码转成字节数组
```

-> 将上一步的返回值前24位赋值给byte数组：key，24位之后的8位赋值给byte数组：offset

-> 加密 key是密钥，offset是位移量 data是要加密的数据

```java
String hex = "";
try{
  SymEncryptOperator op = crypt.BOC_EncryptInit(BocSymmetricCrypt.ALG_3DES_CBC, BocSymmetricCrypt.PADDING_PKCS7, 	 key, offset);
	byte[] arr = crypt.BOC_Encrypt(op, data.getBytes(charset));
	byte[] bytes = coder.BOC_Base64(arr, arr.length, BocCoder.ENCODE);
	hex = new String(bytes, charset);
} catch(Exception e) {
  logger.info(e.toString());
}
return hex;
```



## springBoot

### 拦截器Spring Boot之HandlerInterceptorAdapter

在Spring Boot中我们可以使用HandlerInterceptorAdapter这个适配器来实现自己的拦截器。这样就可以拦截所有的请求并做相应的处理。

**应用场景**

- 日志记录，可以记录请求信息的日志，以便进行信息监控、信息统计等。
- 权限检查：如登陆检测，进入处理器检测是否登陆，如果没有直接返回到登陆页面。
- 性能监控：典型的是慢日志。

在HandlerInterceptorAdapter中主要提供了以下的方法：

- preHandle：在方法被调用前执行。在该方法中可以做类似校验的功能。如果返回true，则继续调用下一个拦截器。如果返回false，则中断执行，也就是说我们想调用的方法	不会被执行，但是你可以修改response为你想要的响应。
- postHandle：在方法执行后调用。
- afterCompletion：在整个请求处理完毕后进行回调，也就是说视图渲染完毕或者调用方已经拿到响应。

![2020-08-13_拦截器7](./总结的图片/拦截器HandlerInterceptor.png)

有时候我们可能只需要实现三个回调方法中的某一个，如果实现HandlerInterceptor接口的话，三个方法必须实现，不管你需不需要，此时spring提供了一个HandlerInterceptorAdapter适配器（种适配器设计模式的实现），允许我们只实现需要的回调方法。
这样在我们业务中比如要记录系统日志，日志肯定是在afterCompletion之后记录的，否则中途失败了，也记录了，那就扯淡了。一定是程序正常跑完后，我们记录下那些对数据库做个增删改的操作日志进数据库。所以我们只需要继承HandlerInterceptorAdapter，并重写afterCompletion一个方法即可，因为preHandle默认是true。



运行流程总结如下：

1. 拦截器执行顺序是按照Spring配置文件中定义的顺序而定的。
2. 会先按照顺序执行所有拦截器的preHandle方法，一直遇到return false为止，比如第二个preHandle方法是return false，则第三个以及以后所有拦截器都不会执行。若都是return true，则按顺序加载完preHandle方法。
3. 然后执行主方法（自己的controller接口），若中间抛出异常，则跟return false效果一致，不会继续执行postHandle，只会倒序执行afterCompletion方法。
4. 在主方法执行完业务逻辑（页面还未渲染数据）时，按倒序执行postHandle方法。若第三个拦截器的preHandle方法return false，则会执行第二个和第一个的postHandle方法和afterCompletion（postHandle都执行完才会执行这个，也就是页面渲染完数据后，执行after进行清理工作）方法。（postHandle和afterCompletion都是倒序执行）
5. 由preHandle 方法的解释我们知道这个方法包括后面要说到的afterCompletion 方法都**只能是在当前所属的Interceptor 的preHandle 方法的返回值为true 时才能被调用** 

**定义一个类继承HandlerInterceptorAdapter，并重写方法**

```java
package com.zxh.demo.config;

import org.springframework.web.servlet.ModelAndView;
import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

/**
 * @author: znn
 * @date: 2020/08/2020/8/4
 * @description 拦截器适配器
 */
public class LogInterceptor extends HandlerInterceptorAdapter {
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        System.err.println("=============preHandle--1=================");
        return true;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        System.err.println("=============postHandle--1=================");
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        System.err.println("=============afterCompletion--1=================");
    }
}
```



WebMvcConfigurerAdapter 抽象类是对WebMvcConfigurer接口的简单抽象（增加了一些默认实现），但在在SpringBoot2.0及Spring5.0中WebMvcConfigurerAdapter已被废弃 。官方推荐直接实现WebMvcConfigurer或者直接继承WebMvcConfigurationSupport

**实现WebMvcConfigurer配置拦截器**

```java
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;

/**
 * @author: znn
 * @date: 2020/08/2020/8/4
 * @description 实现WebMvcConfigurer配置拦截器
 */
@Configuration
public class WebConfig implements WebMvcConfigurer {
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new LogInterceptor());
        registry.addInterceptor(new LogInterceptor2());
    }
}
```

在控制器中写一个方法并访问

```java
package com.zxh.demo.controller;

import com.zxh.demo.model.User;
import com.zxh.demo.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.ui.Model;
import org.springframework.web.bind.annotation.RequestMapping;

import java.util.List;

/**
 * @author: znn
 * @date: 2020/08/2020/8/4
 * @description
 */
@Controller
@RequestMapping("user")
public class UserController {

    private final UserService userServiceImpl;

    @Autowired
    public UserController(UserService userServiceImpl) {
        this.userServiceImpl = userServiceImpl;
    }

    @RequestMapping("query")
    public String query(Model model) {
        List<User> userList = userServiceImpl.queryAll();
        model.addAttribute("userList", userList);
        System.out.println("======主方法======");
        return "layout/hello";
    }
}
```



会在控制台输出

![2020-08-13_拦截器1](./总结的图片/2020-08-13拦截器1.png)



preHandle返回false 则该拦截器及拦截器拦截的主方法都不执行

![2020-08-13_拦截器2](./总结的图片/2020-08-13_拦截器2.png)

主方法发生异常 不执行postHandle 执行afterCompletion

![2020-08-13_拦截器3](./总结的图片/2020-08-13_拦截器3.png)

两个拦截器 按配置顺序执行   postHandle和afterCompletion倒序执行

![2020-08-13_拦截器4](./总结的图片/2020-08-13_拦截器4.png)

第一个拦截器preHandle返回false 

![2020-08-13_拦截器5](./总结的图片/2020-08-13_拦截器5.png)

第二个拦截器preHandle返回false 因为拦截器2返回false 所以拦截器2的postHandle和afterCompletion都不执行     **？拦截器1的postHandle也不执行？**

![2020-08-13_拦截器6](./总结的图片/2020-08-13_拦截器6.png)

主方法发生异常 

![2020-08-13_拦截器7](./总结的图片/2020-08-13_拦截器7.png)









项目及任务管理系统拦截器





![1596445663656](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1596445663656.png)

![1596445692262](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1596445692262.png)

![1596445736052](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1596445736052.png)

![1596445834809](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1596445834809.png)



### BeanDefinitionLoader

**BeanDefinitionLoader**用来注册xml或者javaConfig中的bean，是AnnotatedBeanDefinitionReader的一个简单的外观模式，主要做的工作就是注册bean 。

### LocaleResolver

mvc提供的国际化工具



### MappingJackson2HttpMessageConverter：

springboot默认的json消息转换器



## RestTemplate

### RestTemplate请求参数传递问题

RestTemplate默认传递的是json格式,将参数放在请求体中,这就导致使用@RequestParam接收不到参数.



## git

### git误提交了.idea文件

**删除git的.idea文件**

```shell
git rm --cached -r .idea

git commit -m 'delete .idea'
git push origin develop
```

### 本地项目上传GitHub

1. 进入github新建仓位

2. 打开Mac的终端，输入命令切换到本地需要上传代码的根目录，然后git初始化一下，具体如下图

3. 切换到本地需要上传代码的根目录 git初始化一下 $ git init

4. c 在终端输入命令 把整个代码添加 然后并通过命令写明提交代码的原因

   ```shell
   $ git add .
   $ git commit -m "项目代码上传"
   ```

5. 连接远程仓位

   ```shell
   $ git remote add origin http://github.com/xxx/xxx.git
   ```

6. 在终端上输入命令，拉一下远程的代码，如出现报错“fatal: refusing to merge unrelated histories”，只需要在该命令行添加允许即可“--allow-unrelated-histories”，然后跳出文档说明

![image-20210819135937484](总结的图片/image-20210819135937484.png)

7. 在终端上输入命令，把本地代码全部推送到远程仓库

   ```shell
   $ git push origin master
   ```

   

## RMI（远程方法调用）

一个java虚拟机里的对象远程调用另一个java虚拟机里的对象内的方法，可以用RMI实现。



## EJB（Enterprise Java Bean）企业java bean

是javaEE中面向服务的体系架构的解决方案，可以将功能封装在服务器端，以服务的形式对外发布，客户端在无需知道方法细节的情况下来远程调用方法，大大降低了模块间的耦合性，提高了系统的安全性和可维护性。

EJB底层是用RMI实现的

因为 EJB 过于复杂和笨重，调试非常麻烦，现在都被轻量级的 RPC 框架(Dubbo)及轻量级 Restful 形式的分布式框架 (Spring Cloud) 替代了。





## springCloud

### 组件图

<img src="typora图片/image-20220623160452630.png" alt="image-20220623160452630" style="zoom:50%;" />

### eureka 注册中心

启动注册服务端 可以通过地址访问eureka注册页面

<img src="typora图片/image-20220621104105623.png" alt="image-20220621104105623" style="zoom:50%;" />



### Zookeeper 注册中心

通过指令查看服务注册情况

1.进入docker启动的zooleeper容器

 docker exec -it xxxx  /bin/bash

2.在bin目录下进入zookeeper客户端

 ![img](typora图片/19bedbaeed7c4c149c1a9e5d4facc7e1.png) 

```shell
cd bin/    zkCli.sh 
```

3.启动后查看节点若只有zookeeper一个节点，代表没有服务注册

```shell
ls /

[zookeeper]
```

4.若有[services，zookeeper]两个节点则代表有服务注册，进入查看服务名称 

![img](typora图片/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAamF2YeaYr-S4lueVjOS4iuacgOeJm-eahOivreiogA==,size_8,color_FFFFFF,t_70,g_se,x_16.png) 

```shell
  ls /services
```

5.继续进入可以拿到流水号，根据流水号也可以拿到服务具体信息（不需要此步骤可以忽略）

![img](typora图片/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAamF2YeaYr-S4lueVjOS4iuacgOeJm-eahOivreiogA==,size_20,color_FFFFFF,t_70,g_se,x_16.png) 

> 第5步我没操作成功

### Consul 注册中心

http://127.0.0.1:8500 consul启动后的图形化界面

> 部署可见docker下的配置consul流程

### ribbon 服务调用

之前eureka集成ibbon 后来集成LoadBalance 

### LoadBalance 服务调用

可结合eureka使用，可自定义负载均衡策略

### OpenFeign 服务调用

OpenFeign基于Feign  底层是ribbon

自带负载均衡配置项 集成了ribbon

远程服务调用rpc 

需要定义与调用目标服务接口一致的service方法

<img src="typora图片/image-20220623104301326.png" alt="image-20220623104301326" style="zoom:50%;" />



与服务之间的关系

<img src="typora图片/image-20220623104535138.png" alt="image-20220623104535138" style="zoom:50%;" />

### Hystrix 服务降级（主要讲Hystrix 和阿里巴巴的sentinel）

停止更新了 进入维护，不过理念很优秀 服务==降级、熔断、限流==、监控、隔离...



## 注解

#### @SneakyThrows

偷摸抛出异常

不需要手动处理异常，类似于Lombok的@Data注解，在编译时就已经把处理的代码嵌入到了class内。也可以自定义需要@SneakyThrows处理的异常。

利用泛型将我们传入的Throwable强转为RuntimeException。虽然事实上我们不是RuntimeException。但是没关系。因为JVM并不关心这个。泛型最后存储为字节码时并没有泛型的信息。这样写只是为了骗过javac编译器。源码中注释有解释。

### 总结

- 此注解虽神奇，但慎用。因为一旦用了，如果你的代码遇到了异常，那么在编码阶段你是无法感知的。
- 如果你的代码里没有异常，然而却声明了该注解，反而会引起不必要的误会。
- 还是得看一下[注意事项参考](https://www.jianshu.com/p/f33e3ca7f102)，了解多了之后再决定用不用。否则遇到了问题，就麻烦了。



#### @RequestMapping

接口路径



#### @PathVariable 

映射 [URL](https://so.csdn.net/so/search?q=URL&spm=1001.2101.3001.7020) 绑定的占位符

通过 @PathVariable 可以将 URL 中占位符参数绑定到控制器处理方法的入参中:URL 中的 {xxx} 占位符可以通过

@PathVariable(“xxx”) 绑定到操作方法的入参中。

==一般与@RequestMapping(method = RequestMethod.GET)一起使用==

```java
@RequestMapping("/getUserById/{name}")
    public User getUser(@PathVariable("name") String name){
        return userService.selectUser(name);
    }
//1、若方法参数名称和需要绑定的url中变量名称一致时,可以简写:

@RequestMapping("/getUser/{name}")
    public User getUser(@PathVariable String name){
        return userService.selectUser(name);
    }

//2、若方法参数名称和需要绑定的url中变量名称不一致时，写成:

@RequestMapping("/getUserById/{name}")
    public User getUser(@PathVariable("name") String userName){
        return userService.selectUser(userName);
    }
```



#### @RequestBody

```java
@RequestBody 接受Json数组对象
程序流程：
前台使用ajax技术，传递json字符串到后台；
后台使用Spring MVC注解@RequestBody 接受前台传递的json字符串，并返回新的json字符串到前台；
前台接受后台传递过来的json数据，并显示。
```

注解@RequestBody接收的参数是**来自requestBody**中，即**请求体**。一般用于处理非 `Content-Type: application/x-www-form-urlencoded`编码格式的数据，比如：`application/json`、`application/xml`等类型的数据。

就`application/json`类型的数据而言，使用注解@RequestBody可以将body里面所有的json数据传到后端，后端再进行解析。

GET请求中，因为没有HttpEntity，所以@RequestBody并不适用。

POST请求中，通过HttpEntity传递的参数，必须要在请求头中声明数据的类型Content-Type，SpringMVC通过使用

HandlerAdapter 配置的HttpMessageConverters来解析HttpEntity中的数据，然后绑定到相应的bean上

**@RequestBody(required = fasle)：此参数不是必须传送**



==使用@RequestBody可能会产生的问题==

**GetMapping 不支持@RequestBody 会报错 ，使用PostMapping后面我改成以下代码就没有报错了**

```java
@PostMapping(value="/schedules/findUserSchedule",produces = MediaType.APPLICATION_JSON_VALUE) 

public List<xxxxxx> findUser(@RequestBody xxxxxx xxxxx) {

 log.debug("查询用户日程", xxxxxx); 

 }
```

```
我们在传输json数据的时候，假如json数据为空，那么就会报一个错误，就是Required request body is missing
这个的意思就是我们这个接口必须要传输json格式的数据，假如没有数据，就会报错返回错误的信息。
```

```
在拦截器中使用了request.getInputStream()或者getReader()，然后在controller接口种使用了@requestbody ，这种情况是因为Spring有一个问题就是： ServletRequest中getReader()和getInputStream()只能调用一次。而又由于@RequestBody注解获取输出参数的方式也是根据流的方式获取的。所以我们前面使用流获取后，后面的@RequestBody就获取不到对应的输入流了。这种情况的解决方法可以参考：https://blog.csdn.net/u011277123/article/details/90780329
```



#### @RequestParam

注解@RequestParam接收的参数是来自HTTP请求体或请求url的QueryString中。

RequestParam可以接受简单类型的属性，也可以接受对象类型。

@RequestParam有三个配置参数：

- `required` 表示是否必须，默认为 `true`，必须。
- `defaultValue` 可设置请求参数的默认值。
- `value` 为接收url的参数名（相当于key值）。

**@RequestParam用来处理 Content-Type 为 application/x-www-form-urlencoded 编码的内容，Content-Type默认为该属性，**也可以接收application/json**。@RequestParam也可用于其它类型的请求，例如：POST、DELETE等请求**。

所以在postman中，要选择body的类型为 `x-www-form-urlencoded`，这样在headers中就自动变为了 `Content-Type` : `application/x-www-form-urlencoded` 编码格式。

但是这样不支持批量插入数据啊，如果改用 `json` 字符串来传值的话，类型设置为 `application/json`，点击发送的话，会报错，后台接收不到值，为 `null`。

这时候，注解@RequestBody就派上用场了

[具体解释](https://blog.csdn.net/weixin_38004638/article/details/99655322)

#### @Constraint

```java
@Constraint(validatedBy ={SameTenant.StringChecker.class,SameTenant.LongChecker.class}) 
  这段代表注解的处理逻辑是SameTenant.StringChecker.class和SameTenant.LongChecker.class这两个类，也可以只定义一个，多个用逗号分开。
其中的 validatedBy属性指定了需要进行校验的策略类集合，这是一个数组。
@Constraint(validatedBy = { MobileValidator.class })
也就是说我们定义的注解可以使用@Constraint 进行修饰指定校验策略.
public class MobileValidator implements ConstraintValidator<Mobile, String>
需要自定义一个校验器 MobileValidator,它使用 ValidatorUtil来完成校验的具体逻辑
MobileValidator.java
  这个自定义注解逻辑处理类由于实现了ConstraintValidator接口，所以它默认被spring管理成bean,所以可以在这个逻辑处理类里面用@Autowiredu或者@Resources注入别的服务，而且不用在类上面用@Compent注解成spring的bean.
```



#### @Target

```java
@Target的用法
java.lang.annotation.Target
用于设定注解使用范围
java.lang.annotation.ElementType
Target通过ElementType来指定注解可使用范围的枚举集合
```



#### @Repository

```java
@Repository(value="userDao")注解是告诉Spring，让Spring创建一个名字叫“userDao”的UserDaoImpl实例。
当Service需要使用Spring创建的名字叫“userDao”的UserDaoImpl实例时，就可以使用@Resource(name = "userDao")注解告诉Spring，Spring把创建好的userDao注入给Service即可。

```



### 装配注解 

@Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。

#### @Autowired

@Autowired默认按类型装配（这个注解是属业spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下：

```
`@Autowired` `()` `@Qualifier` `(` `"baseDao"` `)``private` `BaseDao baseDao;`
```

#### @Resource

```java
@Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。
```

@Resource（这个注解属于J2EE的），默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。

```
`@Resource` `(name=` `"baseDao"` `)``private` `BaseDao baseDao;`
```

推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。

#### @Qualifier("service")

```java
在autoware时，由于有两个类实现了EmployeeService接口，所以Spring不知道应该绑定哪个实现类
这个时候就要用到@Qualifier注解了，qualifier的意思是合格者，通过这个标示，表明了哪个实现类才是我们所需要的，我们修改调用代码，添加@Qualifier注解，需要注意的是@Qualifier的参数名称必须为我们之前定义@Service注解的名称之一！
```



@Autowired是根据类型进行自动装配的。如果当Spring上下文中存在不止一个UserDao类型的bean时，就会抛出BeanCreationException异常;如果Spring上下文中不存在UserDao类型的bean，也会抛出BeanCreationException异常。我们可以使用@Qualifier配合@Autowired来解决这些问题。如下：

①可能存在多个UserDao实例

```java
@Autowired  
@Qualifier("userServiceImpl")
public IUserService userService; 
```

或者

```java
@Autowired 
public void setUserDao(@Qualifier("userDao") UserDao userDao) {
    this.userDao = userDao; 
}
```

这样Spring会找到id为userServiceImpl和userDao的bean进行装配。

②可能不存在UserDao实例

```java
@Autowired(required = false) 
public IUserService userService
```

个人总结：

@Autowired//默认按type注入
@Qualifier("cusInfoService")//一般作为@Autowired()的修饰用
@Resource(name="cusInfoService")//默认按name注入，可以通过name和type属性进行选择性注入

 

一般@Autowired和@Qualifier一起用，@Resource单独用。

当然没有冲突的话@Autowired也可以单独用

### 实例化对象到spring容器中

#### @component

```java
@component （把普通pojo实例化到spring容器中，相当于配置文件中的 <bean id="" class=""/>）
```



#### @Component 和 @Bean 的区别

Spring帮助我们管理Bean分为两个部分，一个是注册Bean，一个装配Bean。 
完成这两个动作有三种方式，一种是使用自动配置的方式、一种是使用JavaConfig的方式，一种就是使用XML配置的方式。

@Compent 作用就相当于 XML配置

@Component 

```java
@Component
public class Student {

    private String name = "lkm";

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}
```



@Bean 需要在配置类中使用，即类上需要加上@Configuration注解

```java
@Configuration
public class WebSocketConfig {
    @Bean
    public Student student(){
        return new Student();
    }

}
```



两者都可以通过@Autowired装配

```java
@Autowired
Student student;
```



那为什么有了@Compent,还需要@Bean呢？ 
如果你想要将第三方库中的组件装配到你的应用中，在这种情况下，是没有办法在它的类上添加@Component注解的，因此就不能使用自动化装配的方案了，但是我们可以使用@Bean,当然也可以使用XML配置。

### @Configuration及同类

#### @Configuration

从Spring3.0，@Configuration用于定义配置类，可替换xml配置文件，被注解的类内部包含有一个或多个被@Bean注解的方法，这些方法将会被AnnotationConfigApplicationContext或AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义，初始化Spring容器。

注意：@Configuration注解的配置类有如下要求：

@Configuration不可以是final类型；
@Configuration不可以是匿名类；
嵌套的configuration必须是静态类。
一、用@Configuration加载spring
1.1、@Configuration配置spring并启动spring容器
1.2、@Configuration启动容器+@Bean注册Bean
1.3、@Configuration启动容器+@Component注册Bean
1.4、使用 AnnotationConfigApplicationContext 注册 AppContext 类的两种方法
1.5、配置Web应用程序(web.xml中配置AnnotationConfigApplicationContext)

@Configuation加载Spring方法
@Configuration配置spring并启动spring容器
@Configuration标注在类上，相当于把该类作为spring的xml配置文件中的<beans>，作用为：配置spring容器(应用上下文)

@Configuation总结
 @Configuation等价于<Beans></Beans>

 @Bean等价于<Bean></Bean>

 @ComponentScan等价于<context:component-scan base-package=”com.dxz.demo”/>

原文链接：https://blog.csdn.net/BinshaoNo_1/java/article/details/85005935



#### @ConfigurationProperties详解

spring-boot 提供该注解将配置文件的值映射到类上使用。

通过`@ConfigurationProperties`注解会将值映射到该类中

```java
@ConfigurationProperties("spring.datasource.druid")
class DruidDataSourceProperties {
    .
    .
    .
}
```

通过`@Autowired`标签即可访问到该对象，不过在使用之前必须在使用类上面增加注解  ?`@EnableConfigurationProperties(DruidDataSourceProperties.class)`

属性分析：
@ConfigurationProperties内的值“spring.datasource.druid”代表的是前缀如spring.datasource.druid.testWhileIdle。
也可以写成如下这样，prefix代表前缀，locations 代表映射的文件路径。

```java
@ConfigurationProperties(locations = "classpath:application.yml", 
prefix = "spring.datasource.druid")
```

@ConfigurationProperties的实体还支持分层结构（hierarchical structure）。可以在DruidDataSourceProperties内再建立实体属性。

```java
@ConfigurationProperties("spring.datasource.druid")
public class DruidDataSourceProperties {
	 public static class Stat {  
		    private boolean mergeSql;  
		    private short slowSqlMillis;  
		    // ... getters and setters 
	  }
}
```

代表的含义就是spring.datasource.druid.stat.mergeSql 属性。

原文链接https://blog.csdn.net/u014296316/article/details/79619281



#### @EnableConfigurationProperties





#### @Documented

```java
@Documented注解表明这个注释是由 javadoc记录的，在默认情况下也有类似的记录工具。 如果一个类型声明被注释了文档化，它的注释成为公共API的一部分。指明修饰的注解，可以被例如javadoc此类的工具文档化，只负责标记，没有成员取值。
```





###@Retention

```java
  @Retention可以用来修饰注解，是注解的注解，称为元注解。
Retention注解有一个属性value，是RetentionPolicy类型的，Enum RetentionPolicy是一个枚举类型，
这个枚举决定了Retention注解应该如何去保持，也可理解为Rentention 搭配 RententionPolicy使用。  RetentionPolicy有3个值：CLASS  RUNTIME   SOURCE
按生命周期来划分可分为3类：
  1、RetentionPolicy.SOURCE：注解只保留在源文件，当Java文件编译成class文件的时候，注解被遗弃；
  2、RetentionPolicy.CLASS：注解被保留到class文件，但jvm加载class文件时候被遗弃，这是默认的生命周期；
  3、RetentionPolicy.RUNTIME：注解不仅被保存到class文件中，jvm加载class文件之后，仍然存在；
这3个生命周期分别对应于：Java源文件(.java文件) ---> .class文件 ---> 内存中的字节码。
```



###@常用注解类型

```java
@AssertFalse 校验false
@AssertTrue 校验true
@DecimalMax(value=,inclusive=) 小于等于value，
inclusive=true,是小于等于
@DecimalMin(value=,inclusive=) 与上类似
@Max(value=) 小于等于value
@Min(value=) 大于等于value
@NotNull  检查Null
@Past  检查日期
@Pattern(regex=,flag=)  正则
@Size(min=, max=)  字符串，集合，map限制大小
@Validate 对po实体类进行校验
```



#### @Validated

[原文](https://blog.csdn.net/Mynewclass/article/details/79086372)

```java
SpringMVC验证'@Validated'的使用
```

| 注解                      |                             介绍                             |
| ------------------------- | :----------------------------------------------------------: |
| @Null                     |                        限制只能为null                        |
| @NotNull                  |                       限制必须不为null                       |
| @AssertFalse              |                       限制必须为false                        |
| @AssertTrue               |                        限制必须为true                        |
| @DecimalMax(value)        |               限制必须为一个不大于指定值的数字               |
| @DecimalMin(value)        |               限制必须为一个不小于指定值的数字               |
| @Digits(integer,fraction) | 限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction |
| @Future                   |                   限制必须是一个将来的日期                   |
| @Max(value)               |               限制必须为一个不大于指定值的数字               |
| @Min(value)               |               限制必须为一个不小于指定值的数字               |
| @Past                     |           验证注解的元素值（日期类型）比当前时间早           |
| @Pattern(value)           |                 限制必须符合指定的正则表达式                 |
| @Size(max,min)            |                限制字符长度必须在min到max之间                |
| @NotEmpty                 | 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） |
| @NotBlank                 | 验证注解的元素值不为空（不为null、去除首位空格后长度为0）不同于 @NotEmpty, @NotBlank只应用于字符串且在比较时会去除字符串的空格 |

 

```java
@Validated的分组特性
	第一步：创建分组接口类

分组接口类只是普通的接口类并没有多大意义，只是用来标识这个属性哪种情况下被验证，这类似于java.io.Serializable  
	第二步：Controller方法参数中增加xxx.class接口

在对新增的用户进行ID验证，增加@Validated({addUser.class})接口类用来表示新增的User.getId()需要验证。
	第三步：Bean中添加groups分组

在User实体类中添加groups分组@NotEmpty(groups={addUser.class})与UserController中@Validated({addUser.class})对应，说明在执行saveAddUser新增用户的情况下，才对新增的用户id进行验证。
以上三步就可以简单地完成分组验证，但是对分组验证补充一下三点：

第一是：不分配groups分组时，默认每次都需要验证。

第二是：通过groups分组可以对同一个变量进行多个验证，如下代码
//对用户名进行两次不同情况的验证。
@NotEmpty(groups={First.class})
@Size(min=1,max=10,groups={Second.class})
public String username; 

第三是：默认的情况下，不同的分组约束验证是无序的，但是在有些情况下验证的相互约束很重要（比如前一个组验证失败，后面的将不再验证等情况），所以groups分组的验证也有前后验证顺序。使用@GroupSequence注解进行排序。
/*
 * 分组顺序接口类
 */
import javax.validation.GroupSequence;
//分组序列先Frist再Second
@GroupSequence({First.class,Second.class})
public interface Group{
}
 
@Controller  
public class UserController {  
  
    @RequestMapping("/saveAdd")  
    public String saveAddUser(@Validated({Group.class}) User user, BindingResult result) {  
        if(result.hasErrors()) {  
            return "error";  
        }  
        return "success";  
    }
--------------------- 
```



#### @ControllerAdvice

@ControllerAdvice，是Spring3.2提供的新注解,用在类上

它是一个Controller增强器,可对controller中被 @RequestMapping注解的方法加一些逻辑处理。最常用的就是异常处理，如统一异常处理

统一异常处理
需要配合@ExceptionHandler使用。
当将异常抛到controller时,可以对异常进行统一处理,规定返回的json格式或是跳转到一个错误页面

```java
@ControllerAdvice是一个@Component，用于定义@ExceptionHandler，@InitBinder和@ModelAttribute方法，适用于所有使用@RequestMapping方法。
1、@ModelAttribute注解的方法作用请参考SpringMVC Controller 介绍

2、@InitBinder注解的方法作用请参考SpringMVC Controller 介绍

3、@ExceptionHandler，异常处理器，此注解的作用是当出现其定义的异常时进行处理的方法，其可以使用springmvc提供的数据绑定，比如注入HttpServletRequest等，还可以接受一个当前抛出的Throwable对象。可以参考javadoc或snowolf的Spring 注解学习手札（八）补遗——@ExceptionHandler。

该注解非常简单，大多数时候其实只@ExceptionHandler比较有用，其他两个用到的场景非常少，这样可以把异常处理器应用到所有控制器，而不是@Controller注解的单个控制器。
```



#### @ExceptionHandle

```scala
@ExceptionHandler(value = Exception.class)
def xxx(xxx){
    //对异常的处理
}

```

一个controller中可以有多个被@ExceptionHandler注解的方法，目标方法是其他Handle，优先级是：在异常的体系结构中，哪个异常与目标方法抛出的异常血缘关系越紧密，就会被哪个捕捉到。

捕捉全局的异常
ExceptionHandler只能捕捉同一个controller中的异常，其实我们也有办法捕捉整个程序中所有的异常

新建一个类，加上@ControllerAdvice注解

配合@ControllerAdvice使用。

该注解作用对象为方法，并且在运行时有效，value()可以指定异常类。由该注解注释的方法可以具有灵活的输入参数

原文链接https://blog.csdn.net/qq_21492635/article/details/89381204



#### Spring 事务 注解@Transaction 用法

[原文](https://blog.csdn.net/timchen525/article/details/81517748)

在实际开发中，对于一组数据库操作特别是增删改操作，为了保证原子性，通过需要用事务来控制，要么全部成功，要么全部失败。Spring中可以通过注解@Transaction

需要注意的问题：

（1）尽可能将MySQL执行语句往方法体后面靠：

```java
@Transactional
public void testTransaction(User user) {
    int rowNum = userMapper.insertUser(user);
    doSomething(); // 这个doSomthing 可能耗时较长
    List<User> userList = userMapper.selectAllUsers();
}
```



如果可以移动的话，可以将doSomething()可能耗时较长，移动到int rowNum=userMapper.insertUser(user)的前面，即：

```java
@Transactional
public void testTransaction(User user) {
    doSomething(); // 这个doSomthing 可能耗时较长
    int rowNum = userMapper.insertUser(user);  
    List<User> userList = userMapper.selectAllUsers();
}
```



因为，MySQL事务的commit语句是在第一次执行MySQL相关语句开始，一直到方法的结束。

（2）设置事务的超时时间（如果不设置默认是-1是无限长）

```java
@Transactional(timeout = 5)
public void testTransaction(User user) throws InterruptedException {
    Thread.sleep(2000);
    List<User> userList = userMapper.selectAllUsers(); // 耗时：1s
    int rowNum = userMapper.insertUser(user); // 耗时 1s
    Thread.sleep(3000);
}
```



加入另外两个MySQL相关的操作耗时都是1s，则上述事务是不会报超时异常。

timeout的计算的事务超时 = 最后一个MySQL语句耗时 + 以及最后一个MySQL之前的所有耗时。因此，上述耗时为2s+1s+1s=4s，没有超过5s，因此不会报事务超时异常，这个需要特别注意，如果想了解具体原理，可以查看源码，或者看该文档：http://jinnianshilongnian.iteye.com/blog/1986023

#### @PostConstruct

​    此注解是在Java EE5规范中加入的，在Servlet生命周期中有一定作用，它通常都是一些初始化的操作，但初始化可能依赖于注入的其他组件，所以要等依赖全部加载完再执行。与之对应的还有@PreDestroy，在对象消亡之前执行，原理差不多，这里不做过多介绍。



PostConstruct注释介绍

总体概括如上，注意其中几个点

1. 要在依赖加载后，对象使用前执行，而且只执行一次，原因在上面已经说了。
2. 所有支持依赖注入的类都要支持此方法。首先，我们可以看到这个注解是在javax.annotation包下的，也就是java拓展包定义的注解，并不是spring定义的，但至于为什么不在java包下，是因为java语言的元老们认为这个东西并不是java核心需要的工具，因此就放到扩展包里（javax中的x就是extension的意思），而spring是支持依赖注入的，因此spring必须要自己来实现@PostConstruct的功能。
3. 文档中说一个类只能有一个方法加此注解，但实际测试中，我在一个类中多个方法加了此注解，并没有报错，而且都执行了，我用的是springboot框架。



PostConstruct注释规则

1. 除了拦截器这个特殊情况以外，其他情况都不允许有参数，否则spring框架会报IllegalStateException；而且返回值要是void，但实际也可以有返回值，至少不会报错，只会忽略
2. 方法随便你用什么权限来修饰，public、protected、private都可以，反正功能是由反射来实现
3. 方法不可以是static的，但可以是final的

所以，综上所述，在spring项目中，在一个bean的初始化过程中，方法执行先后顺序为

Constructor （构造方法）> @Autowired > @PostConstruct

先执行完构造方法，再注入依赖，最后执行初始化操作，所以这个注解就避免了一些需要在构造方法里使用依赖组件的尴尬。

应用：在静态方法中调用依赖注入的Bean中的方法。

原文https://www.cnblogs.com/supercj/p/10303645.html



#### @PreDestroy

​	



#### @Transient

java 的transient关键字的作用是需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。

@transient 就是在给某个javabean上需要添加个属性，但是这个属性你又不希望给存到数据库中去，仅仅是做个临时变量，用一下。不修改已经存在数据库的数据的数据结构。

那么这个注解就可以一用。

只要在你准备添加的临时属性上添加这个注解，然后getter和setter自动完成一下，就可以啦。





### Ehcache缓存注解

#### @Cacheable

表明所修饰的方法是可以缓存的：当`第一次`调用这个方法时，它的结果会被缓存下来，在缓存的有效时间内，以后访问这个方法都`直接返回缓存结果`，`不再执行`方法中的`代码段`。

- 这个注解可以用`condition`属性来设置条件，如果不满足条件，就不使用缓存能力，直接执行方法。
- 可以使用`key`属性来指定key的`生成规则`。

**参数**

-  `value`：缓存位置名称，不能为空，如果使用EHCache，就是ehcache.xml中声明的`cache的name`, 指明将值缓存到哪个Cache中
-  `key`：缓存的key，`默认为空`，既表示使用方法的参数`类型`及参数`值`作为key，支持`SpEL`，如果要引用`参数值`使用井号加参数名，如：`#userId`，
   一般来说，我们的更新操作只需要刷新缓存中某一个值，所以定义缓存的key值的方式就很重要，最好是能够唯一，因为这样可以准确的清除掉特定的缓存，而不会影响到其它缓存值 ，
   本例子中使用实体加冒号再加ID组合成键的名称，如"user:1"、"order:223123"等
-  `condition`：触发条件，只有满足条件的情况才会加入缓存，`默认为空`，既表示`全部都加入缓存`，支持`SpEL`

```kotlin
// 将缓存保存到名称为UserCache中，键为"user:"字符串加上userId值，如 'user:1'
@Cacheable(value="UserCache", key="'user:' + #userId")    
public User findById(String userId) {    
    return (User) new User("1", "mengdee");           
}    

// 将缓存保存进UserCache中，并当参数userId的长度小于12时才保存进缓存，默认使用参数值及类型作为缓存的key
// 保存缓存需要指定key，value， value的数据类型，不指定key默认和参数名一样如："1"
@Cacheable(value="UserCache", condition="#userId.length() < 12")    
public boolean isReserved(String userId) {    
    System.out.println("UserCache:"+userId);    
    return false;    
}
```

#### @CachePut

与@Cacheable不同，@CachePut`不仅会缓存方法的结果`，`还会执行`方法的代码段。它支持的属性和用法都与`@Cacheable`一致。一个缓存后就不执行代码了，一个还要执行)

#### @CacheEvict

与@Cacheable功能相反，@CacheEvict表明所修饰的方法是用来`删除失效`或`无用`的缓存数据。

**参数**

- value：缓存位置名称，不能为空，同上
- key：缓存的key，默认为空，同上
- condition：触发条件，只有满足条件的情况才会清除缓存，默认为空，支持SpEL
- `allEntries`：true表示清除value中的`全部缓存`，`默认为false

```csharp
//清除掉UserCache中某个指定key的缓存    
@CacheEvict(value="UserCache",key="'user:' + #userId")    
public void removeUser(User user) {    
    System.out.println("UserCache"+user.getUserId());    
}    

//清除掉UserCache中全部的缓存    
@CacheEvict(value="UserCache", allEntries=true)    
public final void setReservedUsers(String[] reservedUsers) {    
   System.out.println("UserCache deleteall");    
}
```



链接：https://www.jianshu.com/p/154c82073b07



### 自定义注解

1、 什么是注解
	注解：Annontation，是Java5中引进的新特性，提供了一种安全的类似注解的机制，包含在Java.lang.annotation包中。用来将任何的信息和元数据或者程序元素（如：类，方法，成员变量）
	进行关联。为程序的元素（类，方法，成员变量）加上更直观更明了的说明。像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及
	本地参数的声明语句中。
2、	注解的用处
	1)生成文档，常用的@param，@return
	2)跟踪代码依赖性，实现替代配置文件功能，如Dagger2
	3)在编译时进行格式检查 如@override
3、	注解的原理
	注解的本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象$Proxy1.
	通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的
	来源是Java常量池。
4、	元注解
	Java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候需要用到元注解）
	@Documented	-注解是否包含在javaDao中
	@Retention	-什么时候使用该注解
	@Target	-注解用于什么地方
	@Inherited	-是否允许子类继承该注解
5、	四种元注解详解
	1) @Retention	-定义该注解的声明周期，三种参数
	

		@Retention(RetentionPolicy.SOURCE)：在编译阶段丢弃。这类注解在编译结束以后就不在有任何意义，所以他们不会写入字码节
											@override，@SupperessWarnings都属于这类注解
		@Retention(RetentionPolicy.CLASS)：在类加载的时候丢弃。在字节码文件的处理中有用,注解默认使用这种方式
		@Retention(RetentionPolicy.RUNTIME)：始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。
		（常用方法）


​	
​	2) @Target	-表示该注解用于什么地方。默认值为任何元素，表示该注解用于什么地方，可用的ElementType参数如下
​		

		ElementType.CONSTRUCTOR：用于描述构造器
		ElementType.FIELD:	用于描述方法
		ElementType.PACKAGE:	用于描述包
		ElementType.PARAMETER：	用于描述参数
		ElementType.TYPE：	用于描述类，接口（包括注解类型）或enum声明


​		
​	3) @Documented	-一个简单的Annotations标记注解，表示是否将注解信息添加在Java文档中


​	
​	4) @Inherited	-定义该注释和子类的关系
​		

		@Inherited元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于
				  一个class，则这个annotation将被用于该class的子类

6、常见标准的Annotation：

	1)Ovveride
		java.lang.override	是一个标记类型注解，它被用作标注方法。说明了被标注的方法重载了父类的方法，起到了断言的作用，如果我们使用了这种注解在一个没有覆盖
							父类的方法时，Java编译器将以一个编译错误来警示
		注：断言功能是用于软件的开发和测试的，也就是说，删去断言的那部分语句后，你程序的结构和运行不应该有任何改变，千万不要把断言当成程序中的一个功能来使用
		
	2)Deprecated
		Deprecated也是一种标记类型注解。当一个类型或者类型成员使用@Deprecated修饰的话，编译器将不鼓励使用这个被标注的程序元素。所以使用这种修饰具有一定的“延续性”，
		如果我们在代码中继承或覆盖的方法使用了这个过时的类型或者成员，虽然继承或者覆盖后的类型或者成员并不是被声明为@Deprecated，但编译器仍然要报警。
	
	3)SupperessWarnings
		SupperessWarning 不是一个标注类型注解。它有一个类型为String[]的成员，这个成员的值被禁止的警告名。对于javac编译器来讲，被-Xlint选项有效的警告名也同样对
		@SupperessWarnings有效，同时编译器忽略掉无法识别的警告名。
		@SuppressWarnings("unchecked") 告诉它对被批注的代码元素内部的某些警告保持静默。

7、自定义注解编写的规则
	

	1)Annontation型定义为@interface，所有的Annotation会自动继承Java.lang.Annotation这一接口，并且不能再去继承别的类或是接口
	2)参数成员只能用public或者默认(default)这两个访问权限
	3)参数成员只能用基本类型byte、short、char、int、long、float、double、boolean八种基本数据类型和String、Enum、Class、annotations等数据类型，已经这一些类型的数组
	4)要获取类方法和字段的注解信息，必须通过Java的反射技术来获取Annotation对象，因为除此之外没有别的获取注解对象的方法
	5)注解也可以没有定义成员，不过这样注解就没啥用了
	6)自定义注解必须使用到元注解



## URI URL

### URI URL的区别和关系

统一资源标志符URI就是在某一规则下能把一个资源独一无二地标识出来。
以人为例子 通过身份证号能让我们能且仅能确定一个人。

那统一资源定位符URL同样可以标识一个资源。拿人做例子跟HTTP的URL做类比：

动物住址协议://地球/中国/浙江省/杭州市/西湖区/某大学/14号宿舍楼/525号寝/张三.人

可以确定唯一的一个人，起到了URI的作用，所以URL是URI的子集。

URL是以描述人的位置来唯一确定一个人的。
在上文我们用身份证号也可以唯一确定一个人。对于这个在杭州的张三，我们也可以用：

身份证号：[123456789](tel:123456789)

来标识他。
所以不论是用定位的方式还是用编号的方式，我们都可以唯一确定一个人，都是URl的一种实现，而URL就是用定位的方式实现的URI。

回到Web上，假设所有的Html文档都有唯一的编号，记作html:xxxxx，xxxxx是一串数字，即Html文档的身份证号码，这个能唯一标识一个Html文档，那么这个号码就是一个URI。
而URL则通过描述是哪个主机上哪个路径上的文件来唯一确定一个资源，也就是定位的方式来实现的URI。
对于现在网址我更倾向于叫它URL，毕竟它提供了资源的位置信息，如果有一天网址通过号码来标识变成了[http://741236985.html](https://link.zhihu.com/?target=http%3A//741236985.html)，那感觉叫成URI更为合适，不过这样子的话还得想办法找到这个资源咯…



## 设计模式

### 原则

1.单一职责原则 

2.开闭原则 

3.依赖倒转原则：

高层模块不应该依赖于底层模块，两个都应该依赖抽象

抽象不应该依赖细节，细节应该依赖于抽象（针对接口编程，不要针对实现编程）。

4.里氏替换原则：

子类必须能够替换掉它们的父类型。

### 单例模式

### 工厂模式

### 建造者模式



## cmd常用指令

### 查杀进程

在启动程序时有时会出现端口占用问题 这时候就需要通过指令查找占用端口的进程 如果没有影响就将此进程杀掉

如 查找占用 9088 的进程

**根据端口查找网络连接 查找指定端口的进程**

- 查找端口为9088的网络连接
- netstat -nao|findstr "9088"

![查杀进程图1](./总结的图片/查杀进程图1.png)

**查找进程**

- 从进程列表中查找包含指定字符串的进程
- tasklist|findstr "10104"

![查杀进程图2](./总结的图片/查杀进程图2.png)

**结束进程**

- taskkill /pid 10104 -f



### Mac查杀进程

1. 通过命令`lsof -i:8443` 查看占用端口号的进程号，参考如下:
   ![在这里插入图片描述](https://img-blog.csdnimg.cn/61700f1fee2048a3bbf7ed9edf95437c.png)
2. 拿到PID为7520后，使用命令 `kill 7520`关闭进程
3. 如果第二步还是无法关闭进程，那么建议直接通过Mac的活动监视器，一样能够通过PID找到对应进程，如下：
   ![img](https://img-blog.csdnimg.cn/4f19c20af3574098adb0a0a53e352d6f.png)
   然后强制退出就好。

### 日志

在项目的开发中由于对于log4j、logback以及slf4j之间的关系和相关的知识不能清晰掌握，在业余时间进行记录。

#### 1、三者之间的关系

1）　

简答的讲就是slf4j是一系列的***\*日志接口\****，而log4j logback是具体实现了的***\*日志框架\****。

　 因为是接口，所以在项目中如果你不引用log4j 、logback或者其它日志框架你会发现，由于没有给出具体的logger实现，

　 控制台是不能够正常的输出日志信息。也就是说我们在具体开发中，需要绑定一个日志框架，才能正常的使用slf4j。

2）　　

  log4j和logback就是两个受欢迎的日志框架。但两者又有不同：

　　　log4j是apache实现的一个开源日志组件。包的实现（Wrapped implementations）

　　　logback同样是由log4j的作者设计完成的，拥有更好的特性，用来取代log4j的一个日志框架。是slf4j的原生实现。（Native implementations）

　　 log4j配置文件需要web.xml文件完成加载，logback.xml文件无需，只要放在资源根路径下就好。

 3）

总结：

　　slf4j是java的一个日志门面，实现了日志框架一些通用的api，log4j和logback是具体的日志框架，他们可以单独的使用，也可以绑定slf4j一起使   用。

　　单独使用：分别调用框架自己的方法来输出日志信息。

　　绑定slf4j一起使用：调用slf4j的api来输入日志信息，具体使用与底层日志框架无关（需要底层框架的配置文件）



　　显然这里我们不推荐单独使用日志框架。假设项目中已经使用了log4j，而我们此时加载了一个类库，而这个类库依赖另一个日志框架。这个时候我们就需要维护两个日志框架，这是一个非常麻烦的事情。而使用了slf4j就不同了，由于应用调用的抽象层的api，与底层日志框架是无关的，因此可以任意更换日志框架。

#### 2、日志级别

log4j提供了4种日志级别和2种日志开关。logback与其一样，logback的日志级别定义在ch.qos.logback.classic.Level类中。
log4j官方网址: http://logging.apache.org/log4j/1.2/

4种级别：

DEBUG：输出调试信息；指出细粒度信息事件对调试应用程序是非常有帮助的。 
INFO： 输出提示信息；消息在粗粒度级别上突出强调应用程序的运行过程。 
WARN： 输出警告信息；表明会出现潜在错误的情形。 
ERROR：输出错误信息；指出虽然发生错误事件，但仍然不影响系统的继续运行。 
FATAL： 输出致命错误；指出每个严重的错误事件将会导致应用程序的退出。 

2个日志开关 ：
ALL level：打开所有日志记录开关；是最低等级的，用于打开所有日志记录。 
OFF level：关闭所有日志记录开关；是最高等级的，用于关闭所有日志记录。

按照范围从小到大排序：

OFF level > FATAL > ERROR > WARN > INFO > DEBUG > ALL level；范围大的会包含范围小的，例如日志设置为INFO级别的话则FATAL、ERROR、WARN、INFO的日志开关都是打开的，而DEBUG的日志开关将是关闭的。

建议：

Log4j或logback建议只使用四个级别，优先级从高到低分别是 ERROR、WARN、INFO、DEBUG。

## MySql

### InnoDB聚簇索引 非聚簇索引

**聚簇索引**：叶子结点存储行记录（不是行地址而是行记录），一个表必须有且只有一个聚簇索引。

1.如果一个表定义了PK（主键）那PK就是聚簇索引。

2.如果没有定义PK，那么第一个NOT NULL UNIQUE的列就是聚簇索引。

3.否则InnoDB会另外创建一个隐藏的ROWID作为聚簇索引。

这种机制使得基于PK的查询速度非常快，因为直接定位的行记录。

**非聚簇索引**：二级索引、辅助索引。叶子结点存储主键值（MyISAM则是存储的行记录头指针）。

普通索引无法直接定位行记录。

### 回表查询

假设有个t表(id PK, name KEY, sex, flag)，这里的id是聚集索引，name则是普通索引。

表中有四条记录：

|      id|    name  |    sex  |      flag|
| ---- | ---- | ---- | ---- |
| 1 | Sj | m | A |
| 3 | zs | m | A |
| 5 | ls | m | A |
| 9 | Ww | f | B |



聚簇索引的B+树索引（id是PK，叶子结点存储行记录）

![InnoDB聚簇索引](./总结的图片/InnoDB聚簇索引.png)

非聚簇索引的B+树索引（普通的索引）

![非聚簇索引](./总结的图片/InnoDB非聚簇索引.png)

普通索引无法直接定位行记录，其查询过程通常需要扫描两遍索引树

select * from t where name = 'ls';

执行过程

![使用普通索引](./总结的图片/扫描索引树.png)

粉色的路径需要扫描两遍索引树，第一遍先通过普通索引定位到主键值id=5，然后第二遍通过聚簇索引定位到具体行记录。这就是回表查询

### mysql字符集

```mysql
-- 查看数据库支持的所有的字符集(这句命令自己下去操作)。
mysql> show character set;
-- 查看系统当前状态，里面可以看到部分字符集设置。
mysql> status;
-- 查看系统字符集设置，包括所有的字符集设置
mysql> show variables like '%char%';
```



connection：连接器，用来进行“编码转换过程”的。

client--> connection-->mysql服务器 server

```mysql
-- 1）设置客户端的字符集。
set character_set_client=gbk;
-- 2）设置连接器的字符集。
set character_set_connection=utf8;
-- 3）设置返回结果的字符集。
set character_set_results=gbk;
```

**产生乱码的两个原因**

（1）解码和实际编码不一致导致的乱码，可修复。如果客户端字符集和返回结果字符集不一致，查询出的结果会乱码。

将返回结果的字符集设置为和编码一致，则可修复。

（2）传输过程中，由于编码不一致，导致部分字节丢失，造成的乱码，不可修复。

mysql服务器默认使用 latin1 字符集 不支持中文，存入中文会丢失字节

### using(字段名)

```sql
select id,s.name,s.age,t.core from student t inner join teacher using(id);
using关键字的使用规则就是等值连接而且连接的字段名称和字段类型必须要一致。
对于using关键字指定的列名 在查询中是不能使用表名或者表别名的。
```

### 查看或显示数据库

show databases;

### 进入数据库

use [数据库名]

### 查看数据库内所有的表

show tables;

### 查看所在当前数据库

select database();

### 取消外键约束

SET FOREIGN_KEY_CHECKS = 0;



### 恢复外键约束

SET FOREIGN_KEY_CHECKS = 1;



一般在插入测试数据前后加上这两句，先忽略外键约束，方便数据插入，然后恢复外键约束



### WHERE 1 = 1

```sql
select * from user where 1=1
```

**where1=1是有特殊意义的**，包含以下两种情境：**动态SQL拼接**和**查询表结构**。

**一  动态SQL拼接**

适合多条件搜索，当要构造动态sql语句时**为了防止sql语句结构不当**,所以加上where 1=1 ，这样SQL语句不会报错

当两个if 都不成立的时候，或者仅有第一个if 成立的时候，SQL语句拼接就会出现错误。当我们的SQL语句加上where 1=1的时候，就不报错了，如下：

```sql
String sql="select * from table_name where 1=1";
if( conditon 1) {
  sql=sql+" and var2=value2";
}
if(conditon 2) {
  sql=sql+" and var3=value3";
}
```

SQL语句加上where 1=1，只是为了满足多条件查询页面中不确定的各种因素而采用的一种构造一条正确能运行的动态SQL语句的一种方法。

**二  查询表结构**

优点：数据库开销小。

where 1=1是sql语句条件逻辑判断表达式，由于1=1成立，恒为真，该表达式1=1将始终返回"真"。这种写法实际**目的是为了获取逻辑值"True",**其实诸如2=2, 1+2=3，'中'='中'等之类的写法都可以返回逻辑值"True"，只不过1=1的运算开销更小，故被应用的最普遍。下面例子将有助于理解有关概念:

```javascript
1) select * from t1 where 1=1;
-- 实际等效于select * from t1 where true;-- 语句将返回t1中所有的记录行

2) select * from t1 where 1<>1;
-- 实际等效于 select * from t1 where false;-- 语句将返回空记录集
```

说明：例1)实际上等同于不加任何筛选条件，有些画蛇添足，where 1=1的实际意义不如**where 1<>1(或者where 1=0)**来得有用，**当我们只需要获取表的字段(结构)信息，而不需要理会实际保存的记录时，例2)的写法将是非常可去取的，因为系统仅会读取结构信息，而不会将具体的表记录读入内存中，这无疑节省了系统开销。**



### jdbcTemplate.batchUpdate(sqlList.toArary: _*)

批量执行





### xxx.nextval

1.创建序列

下面的示例创建名为 DecSeq 使用一个序列 十进制 具有介于 0 到 255 之间的数据类型。

```sql
CREATE SEQUENCE Test.DecSeq  
    AS decimal(3,0)   
    START WITH 125      /* 序列从125开始 */
    INCREMENT BY 25  	/* 每次生成数字时递增25 */
    MINVALUE 100  		/* 序列最小值100 */
    MAXVALUE 200  		/* 序列最大值200*/
    CYCLE  				/* 当值超过最大值 200 时，序列将从最小值 100 重新开始。 */
    CACHE 3 			/* 缓存<常量> 通过最大限度地减少生成序列编号所需的磁盘 IO 数 */
; 
```

decimal：序列可定义为任何整数类型。 允许使用下面的类型。　　
　　tinyint -0 到 255 范围

　　smallint -范围-32,768 到 32,767

　　int -范围-2,147,483,648 到 2,147,483,647

　　bigint -范围-9223372036854775808 到 9223372036854775807

　　十进制 和 数值 小数位数为 0。

　　如果未不提供任何数据类型， bigint 数据类型用作默认值。
`START WITH`：启动值 <常量> ，序列对象返回的第一个值。启动 值必须是值小于或等于最大值并大于或等于序列对象的最小值。 新序列对象的默认起始值是升序序列对象的最小值和降序序列对象的最大值。

`INCREMENT`：增量值<常量>，该值用于递增(或递减)，每次调用序列对象的值 NEXT VALUE FOR 函数。 如果增量是负值，则序列对象为降序，否则为升序。 增量不能为 0。 新序列对象的默认增量为 1。

`MINVALUE`：指定序列对象的边界。 一个新序列对象的默认最小值是该序列对象的数据类型的最小值。 对于 tinyint 数据类型，此值为零，对于所有其他数据类型则为负数。

`MAXVALUE`：指定序列对象的边界。 一个新序列对象的默认最大值是该序列对象的数据类型的最大值。

`CYCLE`：[周期 | NO CYCLE]此属性指定当超过序列对象的最小值或最大值时，序列对象是应从最小值（对于降序序列对象，则为最大值）重新开始，还是应引发异常。 新序列对象的默认循环选项是 NO 。请注意，循环不从起始值重新开始，而是从最小值或最大值重新开始。

`CACHE`：缓存<常量> 通过最大限度地减少生成序列编号所需的磁盘 IO 数，可以提高使用序列对象的应用程序的性能。 默认值为 CACHE。



### case when xxx then xxx else xxx end

条件判断 一般用在select后

例子：当更新日期不为空，以更新日期为条件查询，否则以创建日期为条件查询

```sql
select t.* from 表名 t where (case when t.last_mod_time is not null then t.last_mod_time else t.creat_time end) between '20200420000000' and '20200420235959'
```



### NVL判空

例子：当更新日期不为空，以更新日期为条件查询，否则以创建日期为条件查询

```sql
select t.* from 表名 t where NVL(t.last_mod_time, t.creat_time end) between '20200420000000' and '20200420235959'
```



###unpivot 行转列



### [获取时间](https://blog.csdn.net/jojoy_828/java/article/details/2278553)



```sql
select sysdate+30/(24*60*60)
```



sysdate表示为系统当前时间。
sysdate+30/(24\*60\*60) 则表示当前时间的下一30秒。

总之记住，30/(24\*60\*60)中的(24\*60\*60)这一截为计算的标准单位，24*60*60就是以秒为单位，24*60则是以分为单位，那24当然是以小时为单位啦。

sysdate+30/(24\*60\*60) 就是表示当前时间的后30秒；
sysdate+30/(24*60)    就是表示当前时间的后30分；
sysdate+30/24       就是表示当前时间的后30个小时；



### over(partition by xxx order by yyy)分组

将数据根据 xxx 字段分块（组）展示，根据 yyy字段 在组内排序



### for in loop 循环更新

用法：目的更新B表的数据

查询出A表的字段，命名为表1。然后更新B表

```sql
BEGIN
 FOR 表1 IN (
SELECT [匹配字段]，[更新字段] FROM A表
 ) loop
UPDATE B表
SET B表.[需要更新字段]= 表1.[更新字段]
WHERE
 B表.[匹配字段]= 表1.[匹配字段];
END loop ;
END;
```

实例

```sql
BEGIN
 FOR r IN (
  SELECT
   A .*,
   b.SHORTLIST_EXPIRE_DATE old_SHORTLIST_EXPIRE_DATE
  FROM
   TMP_20180126_ZSX A,
   SP_PARTNER_INFO b
  WHERE
   A .PARTNER_CODE = b.PARTNER_CODE
 ) loop
UPDATE SP_PARTNER_INFO
SET SHORTLIST_EXPIRE_DATE = r.SHORTLIST_EXPIRE_DATE
WHERE
 PARTNER_CODE = r.PARTNER_CODE;
END loop ;
END;
```

[地址](https://www.cnblogs.com/chenliugou/p/11174943.html)

### 自动补全位数LPAD左补位  RPAD右补位

```sql
-- 5 左补0 直到变成7位
SELECT LPAD(5,7,'0') FROM DUAL;
-- 结果  0000005
-- 5 左补0 直到变成7位
SELECT LPAD(5,7,'0') FRO M DUAL;
-- 结果  5000000
```



### ORA-01461: 仅能绑定要插入 LONG 列的 LONG 值

当向ORACLE数据库中插入或更新数据时，报错“ORA-01461: 仅可以为插入 LONG 列的 LONG 值赋值”，可能有以下几种原因：
1、插入到字符串长度大于4000字节。
2、插入到表中的记录的某个字段数据的实际长度大于2000个字节（如果是UTF-8，则是1333个字节）；或者是插入的记录中有两个或两个以上长度大于2000字节的字符串。
3、数据库与客户端的JDBC 驱动不匹配。对于UTF-8或欧洲的某些字符集，oracle在存储时，对于一个字符需要2个或3个字节的存储空间，虽然表定义中为 varchar2(4000)，但是其实该字段的data_length为其2倍或3倍长。这种情况下oracle会把data_length长度超过 4000的当做LONG型处理，你的表中有两个这样的字段，插入数据时相当于同时操作2个LONG字段。



### 重置自增id值

MYSQL在创建一个带有自增[主键](https://so.csdn.net/so/search?q=主键&spm=1001.2101.3001.7020)ID的表时，通常在删除数据时，导致自增主键不连续了。使用下面的SQL脚本可以重置主键。

```MySQL
-- 1、重置已有数据主键
SET @rownum = 0;
UPDATE table_name SET id = @rownum := @rownum +1;

-- 2、修改自增主键，beginIndex为查询出来的最大id+1
SELECT max(id)+1 from table_name;
alter table table_name auto_increment= beginIndex;
```





### 遇到的问题

#### ORA-00913  值过多

1.查询语句：子查询返回了太多列

2.insert语句：插入的数据多余定义表时的数据



## oracle

### 判断条件in(?, ?, ?) 和 in(select ...)

第一种写法 in(?, ?, ?)中的数据有个数限制，大于1000个sql会报错，如果是大批量的数据，为了避免这种情况发生，可以在in()中放入子查询sql 经检测，子查询结果数量大于1000结果也是正确的

### merge into

**无法在源表中获得一组稳定的行**

因为一条主表信息对应多条副表信息



### Synonyms同义词

Oracle中同义词是任何表、视图、物化视图、序列、存储过程、函数、包、类型、JAVA类对象、用户定义类型,或是其他的同义词的别名。由于其只是一个别名，所以除了在

   数据字典中的定义不占任何空间。

创建同义词

Create or replace synonym 同义词 for 用户名.表名;



### 数据库连接 db link

一. 实现结果：在一个数据库中某个用户下编写一个存储过程，在存储过程中使用DBLINK连接另一个数据库，从此数据库中的一个用户下取数，然后插入当前的数据库中的一个表中。

 

二. 实现方法步骤：

  \1. 创建存储过程

  \2. 在存储过程中先创建database link

  \3. 创建成功

  \4. 从另一个数据库取出数据插入到当前数据库中

  \5. 任务完成 

三. 创建DBLINK的方法：

```sql
create public database link dblink
 
       connect to totalplant identified by totalplant 
 
       using '(DESCRIPTION =
                (ADDRESS_LIST =
                  (ADDRESS = (PROTOCOL = TCP)(HOST = LOCALHOST)(PORT = 1521))
                )
                (CONNECT_DATA =
                  (SERVICE_NAME = prd.gdc)
                )
              )';
```



```sql
语法解释：create public database link DBLINK名字(自己随便起)
 
                  connect to 用户名 identified by 密码
 
                  using '(DESCRIPTION =
                            (ADDRESS_LIST =
                              (ADDRESS = (PROTOCOL = TCP)(HOST = 要连接的数据库所在服务器的IP地址)(PORT = 1521))
                            )
                            (CONNECT_DATA =
                              (SERVICE_NAME = 要连接的数据库的在本地的服务名(即要连接的数据库的SID))
                            )
                          )';
```

\2. 如果创建private的DBLINK

```sql
  create database link dblink
 
        connect to totalplant identified by totalplant 
 
        using '(DESCRIPTION =
                (ADDRESS_LIST =
                  (ADDRESS = (PROTOCOL = TCP)(HOST = LOCALHOST)(PORT = 1521))
                )
                (CONNECT_DATA =
                  (SERVICE_NAME = prd.gdc)
                )
              )'; 
```

四. 连接成功后从所连接的数据库中取数的方法：

   \1. select * from tbl_ost_notebook@dblink;

   说明：只需在表名的后面加上"@DBLINK名字"即可。  

五. 在当前数据库下查看所有的DBLINK的方法：

   \1. select * from dba_db_links;   

六. 删除当前数据库下的一个指定的DBLINK的方法：

   \1. 如果创建的是一个public的DBLINK，删除时需要用

​    drop public database link dblink;

   \2. 如果创建的是一个private的DBLINK，删除时需要用

​    drop database link dblink;

   说明：drop public database link DBLINK名字;   

七. 查看当前数据库的全局数据库名的方法：

   \1. select * from global_name;  

八. 查看当前用户具有哪些针对DBLINK的权限的方法：

```sql
SELECT DISTINCT PRIVILEGE AS "Database Link Privileges"
 
        FROM ROLE_SYS_PRIVS
 
        WHERE PRIVILEGE IN ( 'CREATE SESSION','CREATE DATABASE LINK',
 
                             'CREATE PUBLIC DATABASE LINK');
```

**注意：数据库中的字段有clob类型，是不能移过来的：**

　　**解决办法：**

**①创建临时表：这里临时表的表结构与目标表T_TEST相同,这种临时表不占用表空间，而且不同的SESSION之间互相看不到对方的数据.**

```sql
Create global temporary table table_temp on commit delete rows as select * from T_TEST where 1=2; 
```

**需要注意的问题：** 
**`on commit delete rows`会在commit提交的时候清空临时表数据；`ON COMMIT PRESERVE ROWS`则在会话结束的时候清空数据。** 
**②将远程表数据导入临时表**

```sql
insert into table_temp select * from T_TEST@remote  
```

**③将临时表数据导入目标表**

```sql
insert into T_TEST select * from table_temp 
```

八. 参考资料：

​      http://download-west.oracle.com/docs/cd/B19306_01/server.102/b14231/ds_admin.htm#i1008271



### 存储过程

存储过程如同一门程序设计语言，包含数据类型、流程控制、输入和输出、函数库。

一、创建存储过程

create procedure sp_name()
begin
.........
end

二、调用存储过程

1.基本语法：call sp_name()
注意：存储过程名称后面必须加括号，哪怕该存储过程没有参数传递





## redis

Redis 这几年的大热，现在已经替代 Memcached 成为缓存技术的首要中间件，作为大厂的带头兵，在 BAT 里面，Redis 也已经逐渐取代了 Memcached，广泛使用 Redis 作为缓存应用方案。

**1)速度更快**

Memcached 使用的是多线程模型，既然是多线程，就会因为全局加锁而带来性能损耗。而 Redis 使用的是单线程模型，没有锁竞争，速度非常快。

**2)数据类型更丰富**

Memcached 数据类型非常单一，只支持 String 数据类型，在业务实现上就非常有瓶颈。

而 Redis 支持 string(字符串)、hash(哈希)、list(列表)、set(集合)、zset(sorted set:有序集合) 等……丰富的数据类型可以让 Redis 在业务上大展拳脚。

这也是 Redis 能代替 Memcached 最重要的原因之一。

并且，Memcached 值最大上限为：1M，而 Redis 最大可以到：1GB。

**3)数据持久化**

Memcached 不支持持久化，Redis 支持。

缓存服务器断电后，Memcached 的数据是不能恢复的，而 Redis 可以将数据保久化在磁盘中，服务器重启的后可以加载再次使用，不会造成数据断电丢失。

比如，有些数据是直接放在缓存数据库中的，其他地方可能没有备份，如果丢失了，那可能会造成业务影响，这也是 Redis 非常有用的一个保障特性。

## JPA

### JPA是什么

https://www.cnblogs.com/mosoner/p/9494250.html

JPA本身是一种规范，它的本质是一种ORM规范（不是ORM框架，因为JPA并未提供ORM实现，只是制定了规范）因为JPA是一种规范，所以，只是提供了一些相关的接口，但是接口并不能直接使用，JPA底层需要某种JPA实现，JPA现在就是Hibernate功能的一个子集

#### JPA

  JPA全称： Java Persistence API，JPA通过JDK 5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中。
  JPA的出现有两个原因：
  其一，简化现有Java EE和Java SE应用的对象持久化的开发工作；
  其二，Sun希望整合对ORM技术，实现持久化领域的统一。



## graphql 自动生成文档

通过接口 客户端可以自定需要的字段

自动生成文档

依赖包 

如果继承可视化工具 多加依赖包 5.5.0

订阅功能 添加依赖包 

idea有插件js graphql



配置 graphql  在yml文件中、嵌入可视化工具



定义

在 resources下创建graphsqls目录下定义graphqls后缀文件，名称可以根据也需求定义



可以加参数 可以加别名 可以使用片段（参数提出来）



## Scala

### for循环和yield

for循环中的yield会把循环中当前的元素记下来，保存在集合中，循环结束后将返回该集合。

scala中for循环是有返回值的。如果被循环的是Map，返回的就是Map，被循环的是List，返回的就是List。

```scala
scala>val a = Array(1, 2, 3, 4, 5)

a:Array[Int] = Array(1, 2, 3, 4, 5)
```



可以在for循环结构中加上"if"表达式，他们作为测试用，通常被认为是一个守卫，可以把他们与yield语法联合起来用

```scala
scala>for (e <- a if e > 2) yield e

Res1: Array[Int] = Array(3, 4, 5)
```



如果你熟悉 Scala 的 loop 结构, 就会知道在 for 后的圆括号中还可以许更多的事情. 你可以加入 "if" 表达式，或别的语句, 比如下面的例子，可以组合多个 if 语句: 

```scala
def scalaFiles = 
 for { 
  file <- filesHere 
  if file.isFile 
  if file.getName.endsWith(".scala") 
 } yield file 
```



yield 关键字的简短总结: 

针对每一次 for 循环的迭代, yield 会产生一个值，被循环记录下来 (内部实现上，像是一个缓冲区). 
当循环结束后, 会返回所有 yield 的值组成的集合. 
返回集合的类型与被遍历的集合类型是一致的.



### implicit 隐式

1.将方法或变量标记为implicit
2.将方法的参数列表标记为implicit
3.将类标记为implicit

隐式值： 调用的方法里有隐式值时，需要定义一个隐式值后再调用隐式方法，如果定义两个则会匹配失败。

```markdown
def person(implicit name : String) = name
直接调用person会报错
定义一个隐式值后再调用隐式方法

scala> implicit val p = "znn"
p: String = znn
scala> person
res1: String = znn
因为将p变量标记为implicit，所以编译器会在方法省略隐式参数的情况下去搜索作用域内的隐式值作为缺少参数。
但是如果此时你又在REPL中定义一个隐式变量，再次调用方法时就会报错

scala> implicit val p1 = "ddd"
p1: String = ddd
scala> person
<console>:11: error: ambiguous implicit values:
 both value p of type => String
 and value p1 of type => String
 match expected type String
              person
              ^
匹配失败,所以隐式转换必须满足无歧义规则，在声明隐式参数的类型是最好使用特别的或自定义的数据类型，不要使用Int,String这些常用类型，避免碰巧匹配
```

隐式试图：

隐式类



### Iterator.foreach

```
 1：  val abcde = List("a", "b", "c", "d", "e")
 2：  val it = abcde.iterator
 3：  it.foreach {
 4：    a=>
 5：      println(a)
 6：      if(a == "c") {
 7：          it.next()
 8：          println("不合法")
 9：      }
10：  }

结果：
a
b
c
不合法
e


```

第 7 行的 <font color=#FF0000 >it.next()</font> 的值是 <font color=#FF0000 >d</font>  本次循环结束后,下次循环访问的是 d 后的值 <font color="#FF0000">e</font>

> 在 it.foreach 中调用 it.next() 则迭代器指针后移 下次循环获取 it.next() 的后一位元素进行操作。在本案例中跳过了 d  



### 跳出多重循环

```java
//标号label: 通过对循环进行标识 在满足条件的时候 break flag;
flag:
while (true) {
    int byteRead = 0;
    while (byteRead < 5) {
      byteRead += 1;
      if (byteRead % 2 == 0) {
        break flag;
      }
    }    
}

//使用boolean变量做flag，作为外层循环体结束的条件，赋予变量带有业务意义的名字。
int arr[][] = { { 1, 2, 3 }, { 4, 5, 6, 7 }, { 8,9 } };  
boolean found = true;  
System.out.println("arr.length " + arr.length);  
for (int i = 0; i < arr.length && found; i++) {  
  for (int j = 0; j < arr[i].length; j++) {  
    System.out.println("i=" + i + ",j=" + j);  
    if (arr[i][j] == 5) {  
      found = false; // 修改了外层循环中的参数found  
      break; // 跳出循环  
    }  
  }  
}  
```



### <:上边界>:下边界



### Array

> 可变同类对象序列，数组实例化后长度固定，元素值可变



### List

> 不可变的同类对象序列，对某个列表调用方法时，似乎这个列表发生了改变，实际上只是用新的值重建了列表然后再返回。

方法名以 : 结尾，方法被右操作树调用。

Nil是空列表的简写

```scala
List() 或 Nil 空List

val oneTwoTree = List(1, 2, 3)

val oneTwoThree = 1 :: 2 :: 3 :: Nil
```

**计算列表长度**

```scala
List(1, 2, 3).length
Int = 3
```

列表的  length 方法比较费时的操作，为了找到尾部，需要遍历整个列表，其花费的时间与列表元素数量成正比。所以当判断列表是否为空时，应当采用  xs.isEmpty 方法。而不是 xs.length == 0 。

**访问列表尾部： init 方法和 last 方法**

```scala
xs.head   返回（非空）列表的第一个元素
xs.last   返回（非空）列表的最后一个元素
xs.tail   返回除了第一个元素之外余下的列表
xs.init   返回除了最后一个元素之外余下的列表

相同：  对空列表调用这些方法的时候会抛出异常
不同：  head 和 tail 运行的时间都是常量，但 last 和 init 需要遍历整个列表以计算结果。所耗时间与列表长度成正比。
```

**反转列表： reverse 方法**

```scala
scala> abcde.reverse
res1: List[Char] = List(e, d, c, b, a)
*由于列表是不可变的，所以 reverse 创建了新的列表而不是就地改变被操作的列表。
```

**前缀与后缀： drop、 take和 splitfAt**

```scala
xs take n
返回 xs列表的前 n个元素。如果 n大于 xs.length 则返回整个 xs

xs drop n
返回 xs列表除了前 n个元素之外的所有元素。如果 n大于 xs.length 则返回空列表

xs splitAt n  等价于 （xs take n, xs drop n)
返回对偶（pair）列表。
然而， splitAt 避免了对列表 xs的二次遍历
```

**元素选择： apply 方法和 indices 方法**

```scala
abcde apply 2 //Scala中罕见
Char = c

abcde(2) //Scala中罕见
Char = c

xs apply n 等价于 (xs drop n),head
```

列表的索引范围是从 0 到 列表长度-1 。

```scala 
abcde.indices
List[Int] = List(0, 1, 2, 3, 4)
indices 方法可以返回指定列表的所有有效索引值组成的列表。
```

**啮合列表： zip**

```scala
zip操作可以把两个列表组成一个对偶列表：
abcde.indices zip abcde
List[(Int, Char)] = List((0, a), (1, b), (2, c), (3, d), (4, e))

如果两个列表的长度不一致，那么任何不能匹配的元素将被丢掉：
val zipped = abcde zip List(1, 2, 3)
zipped: List[(Char, Int)] = List((a, 1),(b, 2), (c, 3))

常用到的情况是把列表元素与索引值啮合在一起，这时使用 zipWithIndex方法会更为有效，它能把列表的每个元素在列表中的位置值组成一对。
abcde.zipWithIndex
List[(Char, Int)] = List((a, 0), (b, 1), (c, 2), (d, 3), (e, 4))
```



**collect 类似 map**



**companion？**



**drop 和 dropWhile**

drop丢弃前i个元素  dropWhile移除前几个匹配断言函数的元素。



**foldRight  和 foldLeft**

右折叠，左折叠



**span 和 partition 把列表分成 满足条件的一组，其他的另一组**

span 碰到不符合就结束

partition 扫描所有



**slice 截取**



**StringPrefix？**



**takeWhile**

满足条件留下，遇到第一个不满足条件的元素就结束循环。



**toStream?流**



**aggregate?**



**getOrElse**

如果有值，得到这个值，如果没有就会得到一个默认值。

**mapConserve？**



### Tuple

> 元组，不可变，可以包含不同类型的元素。

```scala
	val pair = (99, "Luftballons")
	println(pair._1)
	println(pair._2)

结果：
	99
	Luftballons
```



### Set

![2019-10-16_140533](./总结的图片/2019-10-16_140533.png)

```scala
var jetSet = Set("Boeing", "Airbus") 不可变Set
默认引用不可变Set scala.cloolection.immutable

import scala.collection.mutable.Set
val movieSet = Set("Hitch", "Poltergeist") 可变Set

```



**&、intersect ：求交集、 ++、union：求并集、--、diff求差集**

```scala
scala> Set(1,2,3) & Set(2,4) // &方法等同于interset方法
res1: scala.collection.immutable.Set[Int] = Set(2)
scala> res1.foreach(println)
2
```



**companion？**







### Map

![2019-10-16_143916](./总结的图片/2019-10-16_143916.png)

```scala
创造、初始化、使用可变映射
import scala.collection.mutable.Map

val treasureMap = Map[Int, String]()
treasureMap += (1 -> "Go to isIand.")
treasureMap += (2 -> "Find big X on grountd.")
treasureMap += (3 -> "Dig.")
println(treasureMap(2))
```



**applyOrElse?**



**to?**



**withDefault?**



**++=**



**/:?**





### 从文件里读取文本行

![2019-10-16_154636](./总结的图片/2019-10-16_154636.png)



### Scala 按位运算法则  

![2019-10-16_160718](./总结的图片/2019-10-16_160718.png)





### 过滤器 filter

> if子句





### 伴生类 伴生对象

> 类和它的伴生对象必须在一个源文件里
>
> 类和它的伴生对象可以互相访问其私有成员



### 符号字面量

> 符号字面量 写法  '<标识符>   <标识符> 可以是任何字母和数字的标识符。这种字面量被映射成 预定义类 scala.Symbol 的实例。

符号字面量除了显示名字之外，什么都不能做

符号是被==限定的 (interned)==。如果同一个符号字面量出现两次，那么两个字面量指向的是同一个Symbol对象。



### ==

与Java的区别

scala中的 ==  比较值  ，

​			对所有对象起作用，

​			可以比较不同类型的对象，

​			可以比较null



### match （模式匹配）

match case



### case class

```
case class 与 class 区别：
  * 1.初始化的时候可以不用new，也可以加上，但是普通类必须加new;
  * 2.默认实现了equals、hashCode方法；
  * 3.默认是可以序列化的，实现了Serializable；
  * 4.自动从scala.Product中继承一些函数;
  * 5.case class 构造函数参数是public的，我们可以直接访问；
  * 6.case class默认情况下不能修改属性值；
  * 7.case class最重要的功能，支持模式匹配，这也是定义case class的重要原因。
```



## Linux

### pwd  ls mkdir mv rm 

### Java -jar  程序包 启动程序的命令

### 查看文件内容 more less head tail  cat(cat也可以创建文件)

### grep  -o 统计文件内容  

Grep是linux中自带的文件内容筛选工具,grep使用格式：grep [options]

1.查询：grep [keyword] filename   在filename中查询包含keyword的行

2.显示行号：-n

3.统计次数：-c

4.忽略大小写：-i

5.逆向查找，输出不符合项：-v

### AWK

Awk也是linux中自带的文件内容筛选工具，但是他比grep更加强大，awk可以对文件内容进行切片输出，提取出我们想要的内容;

Awk使用格式：awk [option] ‘条件{print ${num}}’ 

awk 是行处理器 处理庞大文件时不会出现内存溢出或处理缓慢的问题，通常用来格式化文本信息。

.简单分片查找：-F     eg：awk -F”:” ‘{print $0}’ filename

解释：   以冒号切片显示全部（即：$0;   $1  表示显示 第1……）

2.NF          字段数量变量

3.NR          每行的记录号，多文件记录递增

4.$NF                 每行最后一个字段

例：awk -F”:” ‘{print NR，NF，$0}’ filename

5.显示指定行：awk -F: 'NR\==5 || NR==6{print $0}'  /etc/passwd

6.字符匹配：awk '/mysql/{print $0}' /etc/passwd  不匹配：？

7.区间匹配：awk -F: '/mail/,/mysql/{print}' /etc/passwd 

8.字段值匹配：awk -F: '$1~/mail/{print $1}' /etc/passwd

IF语句

必须用在{}中，且比较内容用()扩起来

9.awk -F":" '{if($1=="mysql") print $3}' /etc/passwd

10. awk -F: '{if($1~/mail/) {print $1} else {print $2}}' /etc/passwd

### sort -no 排序

 -n 依照数值的大小排序；-r按照倒叙排列

### uniq -c 统计数量与去重 

-c表示在每列旁边显示该行重复出现的次数 uniq只能处理相邻行，所以要先排序再去重。 

### telnet

telnet [参数] [主机]  通常用来远程登录.

```shell
> telnet localhost 23 连接本地主机 端口号为23

> telnet 192.168.0.8  物理机win10连接虚拟机中的centOS

> ping 192.168.0.5    用telnet实现win10连接win7（需要关闭防火墙） 先测试连通性
> telnet 192.168.0.5
```

### vi/vim  

### cp -rf 

### jps：打印java进程

### jstack [进程号] ：打印线程栈。线程名 优先级 。。。线程状态

### top 查看cpu 内存使用情况. q退出

### zip

zip a.zip /Users/a/Documents/a.txt 压缩文件

zip -e a.zip /Users/a/Documents/a.txt 加密压缩文件

zip -r a.zip /Users/a/Documents/a_folder 压缩文件夹

zip -r -e a.zip /Users/a/Documents/a_folder 加密压缩文件夹

unzip a.zip 解密

unzip a.zip -d /Users/a/Desktop 解密制定目录

## GBase 数据库

连接到云服务器：ssh -p 端口 用户名@ip【ssh -p 22145 root@118.195.185.192】 密码：Gbase1023!@

<img src="总结的图片/image-20211110163456716.png" alt="image-20211110163456716" style="zoom:50%;" />

查看内存信息：free -m    (-m标识以M为单位)

![image-20211117114118296](typora图片/image-20211117114118296.png)

查看服务器配置：df -hT

-h：human 以1024为1G

-t：类型

<img src="总结的图片/image-20211110164002702.png" alt="image-20211110164002702" style="zoom:50%;" />

新建用户和组：useradd gbasedbt

​                           passed gbasedbt

检查用户和组：cat /etc/group|grep gbasedbt

​                           cat /etc/passwd|grep gbasedbt

设置用户密码：passwd gabsdbt

![image-20211117114704343](typora图片/image-20211117114704343.png)



上传文件到服务器：scp -P 22145 /Users/zhangxinhui/Downloads/GBase_8s_Express_Edition.tar root@118.195.185.192:/root

-P 表示端口号、22145表示服务器的端口号,一般不填写表示默认的端口号22

/Users/zhangxinhui/Downloads/GBase_8s_Express_Edition.tar 表示要上传的本地文件

root@118.195.185.192:/root 表示远程文件目录

![image-20211117150022254](typora图片/image-20211117150022254.png)

下载服务器文件到本地



scp -P 27988 root@104.224.166.36:/root/hi.txt  /Users/hill/Desktop/hhh

服务器文件目录root@104.224.166.36:/root/hi.txt

本地文件目录/Users/hill/Desktop/hhh



## docker

docker images 查看本地所有镜像

![image-20210501182858938](总结的图片/docker images.png)

docker search  在Docker Hub（官方提供的镜像仓库）中搜索镜像。

例如**docker search centos**在仓库中搜索centos镜像

![docker serrch](总结的图片/docker search.png)

docker pull 下载镜像

docker rmi 删除镜像 加参数-f强制删除  尽量先删除容器再删除镜像

docker ps 列举出所有运行中的Docker容器 -a列出所有容器 、-f过滤、 -q只列出容器的id 、-l查看最近创建的容器 、-n=XXX 查看最新创建的n个容器

**创建容器**

先创建再启动 或者创建并启动

docker create nginx 创建一个nginx 容器，此时创建的容器并未运行，处于停止状态，容器的 name 是随机生成的，开发者也可以在创建容器时指定 name ，如下：

docker create --name=nginx nginx

**创建容器并启动**

后台型容器：创建并启动容器docker run [镜像] 启动镜像 -d表示后台运行，-P表示随机端口，-p指定端口映射，格式为：ip:hostPort:containerPort。

```shell
docker run --name nginx1 -d -p 8080:80 nginx
```

交互型容器：

也可以创建交互型容器，例如创建一个 ubuntu 容器，开发者可能需要在 ubuntu 上面输入命令执行相关操作，交互型容器创建方式如下：

```shell
docker run --name ubuntu -it ubuntu /bin/bash
```

参数含义都和上文一致，除了 -it，-it 参数，i 表示开发容器的标准输入（STDIN），t 则表示告诉 docker，为容器创建一个命令行终端。

该命令执行完后，会打开一个输入终端，读者就可以在这个终端里愉快的操作 ubuntu 了。

想要退出该终端，只需要输入 exit 命令即可。

**容器启动**

`docker start` 启动的是一个已经存在的容器，要使用该命令启动一个容器，必须要先知道容器的 id 或者 name ，开发者可以通过这两个属性启动一个容器（案例中，nginx 是通过 name 启动，而 ubuntu 则是通过 id 启动）。一般来说，第一次可以使用 `docker run` 启动一个容器，以后直接使用 `docker start` 即可。

docker stop/restart [容器id/name] 停止、重启指定的容器

**容器删除**
1.单个删除： `docker rm` 命令删除一个容器。删除容器时，只能删除已经停止运行的容器，不能删除正在运行的容器。

可以通过 name 或者 id 删除一个容器。如果非要删除一个正在运行的容器，可以通过 -f 参数实现。

2.批量删除：

容器也可以批量删除，命令如下：

```
docker rm $(docker ps -a -q)
```

`docker ps-a-q` 会列出所有容器的 id ，供 rm 命令删除。

**容器内执行命令**

如果容器在后台启动，则可以使用 `docker exec` 在容器内执行命令。不同于 `docker attach` ，使用 `docker exec` 即使用户从终端退出，容器也不会停止运行，而使用 `docker attach` 时，如果用户从终端退出，则容器会停止运行。如docker exec -it mysql-harry bash

![docker exec](总结的图片/docker exec.png)

**查看容器信息**

Docker inspect [容器id/name]

**容器导出**
docker export [容器id/name] > ./xxx/xxx/xx.tar(目录)

**容器导入**
通过执行如下命令可以导入容器（如果自己重新导入，需要记得将 docker 中和 nginx（假如上述导出的是nginx容器） 相关的容器和镜像删除）

cat nginx.tar |docker import -importednging:ilatest

**其他指令**

docker kill 容器id

docker version 查看docker版本信息

docker info 查看docker系统信息

docker build -t 标签名称 目录。构建docker镜像 -t表示指定一个标签 docker tag 为镜像打标签。

docker --help 查看更多命令 如果想查询 run命令的用法 可以使用docker run --help进行查看

**查看dockerip**

ifconfig |grep inet

![image-20210518135509439](总结的图片/image-20210518135509439.png)



### navicat连接docker中的mysql

navicat连接docker后总是会断开

然后需要重新输入密码才能连接

查询解决方法 有可能是因为[Navicat 的版本低与docker 中MySQL加密规则不匹配](https://www.imooc.com/article/70328?block_id=tuijian_wz)

进入docker内的mysql

```shell
> docker exec -it 89c5b9c81e74  bash

root@082aa4abcc90:/# mysql -u root -p

##USE 语句用来完成一个数据库到另一个数据库的跳转。
mysql> USE mysql<数据库名>

```



修改了mysql的加密规则为mysql_native_password

```sql
-- 修改密码为用不过期
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'root';
-- root是密码 根据实际密码调整
Query OK, 0 rows affected (0.02 sec)

-- 修改密码并指定加密规则为mysql_native_password
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
Query OK, 0 rows affected (0.01 sec)

-- 刷新权限
mysql> flush privileges;
Query OK, 0 rows affected (0.01 sec)
```



### docker配置consul

一、拉取consul

```shell
docker pull consul
```

二、

2.1启动

```shell
docker run --name consul1 -d -p 8500:8500 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8600:8600 consul agent -server -bootstrap-expect=1 -ui -bind=0.0.0.0 -client=0.0.0.0
```

2.2命令参数说明

```markdown
-net=host docker参数, 使得docker容器越过了net namespace的隔离，免去手动指定端口映射的步骤

-server consul支持以server或client的模式运行, server是服务发现模块的核心, client主要用于转发请求

-advertise 将本机私有IP传递到consul

-retry-join 指定要加入的consul节点地址，失败后会重试, 可多次指定不同的地址

-client 指定consul绑定在哪个client地址上，这个地址可提供HTTP、DNS、RPC等服务，默认是>127.0.0.1

-bind 绑定服务器的ip地址；该地址用来在集群内部的通讯，集群内的所有节点到地址必须是可达的，>默认是0.0.0.0

allow_stale 设置为true则表明可从consul集群的任一server节点获取dns信息, false则表明每次请求都会>经过consul的server leader

-bootstrap-expect 数据中心中预期的服务器数。指定后，Consul将等待指定数量的服务器可用，然后>启动群集。允许自动选举leader，但不能与传统-bootstrap标志一起使用, 需要在server模式下运行。

-data-dir 数据存放的位置，用于持久化保存集群状态

-node 群集中此节点的名称，这在群集中必须是唯一的，默认情况下是节点的主机名。

-config-dir 指定配置文件，当这个目录下有 .json 结尾的文件就会被加载

-enable-script-checks 检查服务是否处于活动状态，类似开启心跳

-datacenter 数据中心名称

-ui 开启ui界面

-join 指定ip, 加入到已有的集群中
```



2.3 端口说明

```markdown
8500 : http 端口，用于 http 接口和 web ui访问；

8300 : server rpc 端口，同一数据中心 consul server 之间通过该端口通信；

8301 : serf lan 端口，同一数据中心 consul client 通过该端口通信; 用于处理当前datacenter中LAN的gossip通信；

8302 : serf wan 端口，不同数据中心 consul server 通过该端口通信; agent Server使用，处理与其他datacenter的gossip通信；

8600 : dns 端口，用于已注册的服务发现；
```



2.4 查看IP 如：consul1

```shell
> docker inspect --format='{{.NetworkSettings.IPAddress}}' consul1
172.17.0.4
```



三、验证

因为已经开启了UI显示，打开地址如下：http://127.0.0.1:8500/

![image-20220617152615112](typora图片/image-20220617152615112-5450780.png)
————————————————
原文链接：https://blog.csdn.net/weixin_44690195/article/details/124337028



## maven

### pom文件配置



详见cloude2020项目 内的pom文件





### setting文件配置



### Sonatype Nexus私服的仓库管理器

 1.nexus里可以配置3种类型的仓库，分别是proxy、hosted、group 

 

  2.proxy是远程仓库的代理。比如说在nexus中配置了一个central repository的proxy，当用户向这个proxy请求一个artifact，这个proxy就会先在本地查找，如果找不到的话，就会从远程仓库下载，然后返回给用户，相当于起到一个中转的作用。

 

  3.hosted是宿主仓库，用户可以把自己的一些构件，deploy到hosted中，也可以手工上传构件到hosted里。比如说oracle的驱动程序，ojdbc6.jar，在central repository是获取不到的，就需要手工上传到hosted里。

 

  4.group是仓库组，在maven里没有这个概念，是nexus特有的。目的是将上述多个仓库聚合，对用户暴露统一的地址，这样用户就不需要在pom中配置多个地址，只要统一配置group的地址就可以了。



## mac操作

mac显示隐藏文件

终端执行命令：

1.// 设置隐藏文件可见
defaults write com.apple.finder AppleShowAllFiles TRUE

​	  // 设置隐藏文件不可见
​       defaults write com.apple.finder AppleShowAllFiles FALSE

2.重启Finder才可以生效

命令执行： killall Finder



## 前端笔记



### 请求后台方法

1.form表单提交

```html
<form id="submitForm" method="post" th:action="@{/controller/handler}" action="">
    <input.../> ....
</form>
```

2.onclick里写路径

```html
<input type="button" onclick="window.location.href='creat'" th:value="新增" />
```

3.a 标签

```html
<a title="xxx" th:href="@{/xxx/xxx(param1=${param1},param2=${param2})}"></a>
```

4.function里跳转

```html
//a标签调用function
1.   th:οnclick= "'javascript:goRead('+${item.pid}+','+${item.name}+')'"  target="_blank" th:title="${item.title}">

2.   th:onclick="deleteItemType([[${itemType.typeId}]])"  //运行成功过

function xxx(pid,name){
	window.location.href = encodeURI("delete.do?pid=" + pid)
}

3.  th:οnclick="'javascript:member_edit('+${book.getBookName()}+')'"
th:onclick="javascript:addHtkx(\''+${xxx}+'\',\''+${xxx}+'\',\''+${xxx}+'\')'"
```

> 注意window.location.href=‘xxx’路径问题==

```html
1 相对路径
window.location.href='add_affiche.php'; 或
window.location.href='./add_affiche.php';

2 绝对路径
window.location.href='/add_affiche.php';
```



5.ajax跳转

```javascript
$.ajax({
    url:"xxx_ajax",
    data:{
        param: paramValue
    },
    type:"post",
    cache:false,
    dataType:"text",
    async:false,
    success:function(data){
        ...
    }
});
```



#### ajax动态刷新页面  标签值与thymlefyouguan

加载页面时两个都加载出来，一个显示一个不显示

![1586859417078](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1586859417078.png)

```
<div class="follow">
    <span th:style="${checkCollection eq 'false'?'display: block':'display: none'}" id="collection" onclick="addNewCollection()">收藏</span>
    <span th:style="${checkCollection eq 'true'?'display: block':'display: none'}" id="alreadyCol" onclick="cancelCollection()">已收藏</span>
</div>
```

![1586859529070](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1586859529070.png)

这样写，页面样式会有一些问题，但是不会多次请求后台



==有问题== 多次请求后台 前两次没问题，多点几次会大量的发起请求，导致卡顿甚至导致404 原因未明 应该和逻辑有关系  改id和改onclick方法

![1586854585788](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1586854585788.png)

```
$("#alreadyCol").html("收藏");  //
$("#alreadyCol").attr('id','collection');
$("#collection").attr("onclick", '').click(eval(function () {
    addNewCollection()
}));
operateTip("取消成功")
```





### 请求后台并传参

1.form表单提交 表单内的元素按name与后台参数名对应来传值

2.拼接

```js
"xxx?param1="+param1+"&param2="+param2
```



### 调用javascript方法

1、onclick调用

```html
调用带参数的 function
<input type="button" title="xxx" th:onclick="javascript:xxxx(\''+${param}+'\')'" />
```



### 获取页面某个标签的值 如 input的值

1.在jquery中获取

```javascript
var name = $("#name").val();
```



### 提交表单

1、submit按钮提交

```html
例：
<input id="xxx" type="submit" th:value="查询" />
```



2、js中提交

```javascript
例：
function xxx(){
    //提交表单
    var form = $("#mainForm");  //通过表单的id选择表单
    form[0].submit();
}
```

> 思考：下面二者什么区别？

```javascript
$("#mainForm")[0].submit();
这个是JS对象(Form表单)提交
$("#mainForm").submit();
这个是Jquery对象(Form表单)提交
```



### a标签禁止跳转

一、单纯禁止跳转

1.伪协议（不建议用）

```html
<a href="javascript:void(0)" >不能跳转</a> 
```

2.click事件返回false

```html
<a href="http://www.baidu.com"  onclick="return false" >不能跳到百度</a> 
```



二、禁止跳转并执行所需click事件

```html
<a" href="javascript:void(0)" onclick="resetPassword()">重置密码</a>
 
 
function resetPassword(){
    $('#m_modal_1').modal('show');
}
```



原文链接：https://blog.csdn.net/niesiyuan000/article/details/82965102	



### 正则

```javascript
new RegEXP('doctype html')
一：创建一个正则的两种方式：
   例：
   （1：var reg = /abcd/             //"这个叫对象直接量方式"；
   （2：var reg = new RegExp('abcd')  //这个叫构造函数方式；
```



### 标签选择

*#*选择id   *.*选择class





### 为元素添加事件如onclick

```js
1、            // alert("校验成功")
            $("#confirmModal").modal('show');
			$('#confirmModalText').text("确定执行[新增]操作?");
			//提交表单
            $("#confirmModalYes").attr("onclick", '').click(eval(function () {
                commitForm()
            }));
           


1function commitForm() {
        var form = $("#submitForm");
        form[0].submit();
    	loading();
    }

2、
$("#returnModalYes").attr("onclick", "window.location.href = 'delete?typeId=" + typeId + "\'");
```



### 引入其他页面

```html
    <!--引入弹框和提示语-->
    <div th:replace="common/saveresult :: copy"></div>
    <!--loading效果-->
    <div th:replace="common/loading :: copy"></div>
```



### 引入js

```html
<script th:src="@{/webjars/jquery/3.4.1/jquery.min.js}"></script>
<script th:src="@{/webjars/bootstrap/4.4.1-1/js/bootstrap.min.js}"></script>
<script th:src="@{/js/smallJs.js}"></script>
```



#### table中tr的name属性无法通过getElementsByName获取tr元素

  今天写动态生成HTML表格的时候需要用到统计tr内的数据,在生成的时候设置了tr的name属性,但是document.getElementsByName("_test")能获得到这个对象,直接打印显示[object],但是length属性始终是0,不管你添加多少个td名称都设置成"_test"用getElementsByName获得的length总是0 !!!

原因以及解决办法:
    原来在HTML语法里tr td都没有name属性,这得非常得益于上面要感谢的朋友写的文章,并且他提到了没有name的时候getElementsByName会去抓id属性!!所以这里我在动态生成表格的时候把td的id设置成"_test"然后再getElementsByName就能获得到数据正确打印了length。  <font color="red">未验证</font>



### js和jquery方法

**$("#id").get(i)获取dom对象**

在jquery中利用

$("#id")取出的是jquery对象，这是个集合对象，

想要获得dom对象，可以用$("#id").get(i)，其中i是jquery对象序列号，从0开始计算

**js清空点击事件**

```js
$("#id").unbind("click");
```

**js加上点击事件**

```js
$("#id").attr("onclick","functionName()");
```

**js加上带参数的点击事件** 

```js
$("#id").attr("onclick","functionName('"+param1+'\',\''+param2+"')");
```

**js清空tr内的内容**

```js
$("#trName").html("");
```

**js 在tr内加东西**

```js
$("#trName").append(addText);
```



### HTML 5 \<input\> required 属性

required 属性规定必需在提交之前填写输入字段。

如果使用该属性，则字段是必填（或必选）的。

**注释：**required 属性适用于以下 <input> 类型：text, search, url, telephone, email, password, date pickers, number, checkbox, radio 以及 file。

**HTML 4.01 与 HTML 5 之间的差异**

required 属性是 HTML5 中的新属性。

**实例**

带有必填字段的表单：

```html
<form action="demo_form.asp" method="get">
  Name: <input type="text" name="usr_name" required="required" />
  <input type="submit" />
</form>
```



### 前台编码方式

#### escape(param)

特殊字符可编码 后台URLDecoder.decode(param, "编码格式如 UTF-8")解码 但是有些字符不做处理 如+号会转为空格  需要手动转为%2b

问题：如果param中含有中文 则编码后 后台不能直接URLDecoder.decode(param, "编码格式如 UTF-8")解码 会不识别 需做处理如下

```java
/**
* 加码解码工具
* @author lwm
*
*/

public class Encode {

/*
* 对应javascript的escape()函数, 加码后的串可直接使用javascript的unescape()进行解码
*/
public static String escape(String src) {
   int i;
   char j;
   StringBuffer tmp = new StringBuffer();
   tmp.ensureCapacity(src.length() * 6);
   for (i = 0; i < src.length(); i++) {
    j = src.charAt(i);
    if (Character.isDigit(j) || Character.isLowerCase(j)
      || Character.isUpperCase(j))
     tmp.append(j);
    else if (j < 256) {
     tmp.append("%");
     if (j < 16)
      tmp.append("0");
     tmp.append(Integer.toString(j, 16));
    } else {
     tmp.append("%u");
     tmp.append(Integer.toString(j, 16));
    }
   }
   return tmp.toString();
}

/*
* 对应javascript的unescape()函数, 可对javascript的escape()进行解码
*/
public static String unescape(String src) {
   StringBuffer tmp = new StringBuffer();
   tmp.ensureCapacity(src.length());
   int lastPos = 0, pos = 0;
   char ch;
   while (lastPos < src.length()) {
    pos = src.indexOf("%", lastPos);
    if (pos == lastPos) {
     if (src.charAt(pos + 1) == 'u') {
      ch = (char) Integer.parseInt(src
        .substring(pos + 2, pos + 6), 16);
      tmp.append(ch);
      lastPos = pos + 6;
     } else {
      ch = (char) Integer.parseInt(src
        .substring(pos + 1, pos + 3), 16);
      tmp.append(ch);
      lastPos = pos + 3;
     }
    } else {
     if (pos == -1) {
      tmp.append(src.substring(lastPos));
      lastPos = src.length();
     } else {
      tmp.append(src.substring(lastPos, pos));
      lastPos = pos;
     }
    }
   }
   return tmp.toString();
}

}
```



#### encodeURIComponent(param)

还没有实践 据说后台直接URLDecoder.decode(param, "编码格式如 UTF-8")解码即可



### 引入插件

将css和js放入项目 然后在需要的地方引入css和js就可以使用了 记得清缓存



### Shiro与前端结合使用

#### 在前端根据权限展示不同的页面元素

```html
<shiro:hasRole name="权限名称1">
	<input value="权限1" type="text"/>
</shiro:hasRole>
<shiro:lacksRole name="权限名称2">
	<input value="权限2" type="text"/>
</shiro:lacksRole>
```





## Python学习笔记

Windows环境下备份脚本

```python
# Filename: backup_verl.py

import os
import time

source = [r'D:\demo\access', r'D:\demo\access1']

target_dir = 'D:\\demo\\'

target = target_dir + time.strftime('%Y%m%d%H%M%S') + '.zip'

# Linux这一步的代码如下
#zip_command = "zip -qr '%s' %s" % (target, ' '.join(source))
#在 Windows 环境下 %s 不加引号
zip_command = "zip -qr %s %s" % (target, ' '.join(source))

# Run the backup
if os.system(zip_command) == 0:
    print 'Successful backup to', target
else:
    print 'Backup FAILED'
```



### os模块

==os.system==函数 好像在系统中运行命令一样，即在shell中运行 命令--如果命令成功运行，返回0，否则返回错误号。



### 导入模块

```python
import ... as
```

as 可以省略



### Python中的标准模块 

**pickle 和 cpickle存储器**

```python
import cPickle as p

shoplistfile = 'shoplist.data'

shoplist = ['apple', 'mango', 'carrot']

f = file(shoplistfile, 'w')
# 调用存储器模块的 dump 函数， 把对象存储到打开的文件中
p.dump(shoplist, f)

del shoplist

f = file(shoplistfile)
# 使用 pickle 模块的 load 函数的返回来取回对象
storedllist = p.load(file)

print storedlist
```

运行结果：

![1555554664199](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1555554664199.png)



## 遇到的问题

### 启动项目异常

#### 商服投产时项目启动报错

问题原因：因为生产环境用的是jdk1.7 代码里用了jdk1.8里的foreach方法，所以报错。

解决方式：不使用jdk1.8新增的特性。

注意：开发时注意本地环境和生产环境的区别。

#### 连接驱动

```text
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
```

将数据库连接驱动改为最新的

由

```yml
datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://172.20.10.2:3306/zxhRepositry?charset=utf8
    data-username: root
    data-password: root
```

改为

```yml
datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://172.20.10.2:3306/zxhRepositry?charset=utf8
    data-username: root
    data-password: root
```



#### 创建mapper文件错误

因为shiro练习在进行中。有mapper文件，创建了xml 但是没有填内容  配置好即可启动成功



#### 粗心引起的错误 Disconnected

**Disconnected from the target VM, address: ‘127.0.0.1:51458‘, transport: ‘socket‘**

启动springBoot项目报错，第一反应是端口占用，但是端口没有占用。

而且每次启动端口都不一样。

最后发现是yml文件里的数据库连接地址 url 前多了一个空格



#### 根据类名依赖注入了已经删掉的类

```test
Parameter 15 of constructor in com yada. mag service. Orderkxservice required a subfld bean, but 20 weae found

问题原因：在本地跑得起来 部署到服务器启动报错，检查日志文件，存在上面那行错误信息，经过检查，发现是删掉了一个类，但是service里根据类名注入没有删掉，所以注入时不知道注入哪个类。

解决方式：删掉该依赖注入，问题解决。

### 监控功能后台遇到的问题

#### failed to execute goal net.alchim31(Scala-test-compile)

项目启动、打包 报错 

```text
failed to execute goal net.alchim31(Scala-test-compile)

**检查过程**

搜索异常信息：查到的有java和scala不兼容之类的 按照教程修改可以打包成功 但是spring没有启动

最后发现是因为类中有报错 引用了一个还没有创建的类

**解决方式**
解决类中的报错 再启动程序 

**反思**

启动前应该先build 检查代码是否有报错，否则可能浪费大量时间。

#### 无效的sql

**报错信息**
无效的sql

**检查过程**

jdbc执行sql语句报错，将sql修改为最简单的sql还是报错

最后发现是将 类型为 ListBuffer类型的sql转为String类型时 误用了 toString()方法 导致结果成为ListBuffer(select ...) 导致sql无效

**解决方式**

将 toString() 方法改为 mkString

**反思**
查错的时候也看了sql语句，但是没有注意到sql外包了字符串 ListBuffer  想当然的以为这是框架拼接的sql

### 监控功能页面遇到的问题

**$ is not define**

引入的js版本号不对？  后两种可以

​```html
<!--<script src="../static/js/jquery-3.3.1.min.js" th:src="@{/static/js/jquery-3.3.1.min.js}"></script>-->
<!--<script src="http://libs.baidu.com/jquery/1.9.0/jquery.js"></script>-->
<script src="https://s3.pstatp.com/cdn/expire-1-M/jquery/3.3.1/jquery.min.js"></script>
```

**template might not exist or might not be accessible by any of the configured Template Resolvers**

粗心了 ajax访问controller的方法。 

返回数据解析不了。

原因：ajax访问的方法上没有加@ResponseBody   加上就好了

### 加载数据库配置的系统参数

先是百度 查到可以通过继承ApplicationRunner接口  在spring启动时运行run方法  **该方法仅在SpringApplication.run(…)完成之前调用，更准确的说是在构造SpringApplication实例完成之后调用run()的时候**    在run方法里将查询到的数据转为 map 放到**propertySources**中 

然后想在service中通过**@Value**根据key获取value。但是启动报错。取不到值。

应该是因为**执行顺序**的原因：初始化参数是在构造SpringApplication实例完成之后才执行，所以创建service时 没有想要获取到的key-value

所以写在了方法里 通过 enviroment.getProperty("key")取值 取值时调用方法

应该有其他方式吧 目前是这么实现的







### Parameter 1 of constructor in *.Service required a single bean but 20 were found

service里注入了一个范型类，但是这个对应的类被删掉了，根据类名找不到对应的类。删掉多余的注入即可。



### JavaMailSenderImpl发送邮件格式

邮件内容不换行

经过查询 换行符应该使用<br>

然而还是不起作用，发现应该在setText的时候设置content type 为 text/html

```java
public static void main(String[] args) throws MessagingException {
        JavaMailSenderImpl sender = new JavaMailSenderImpl();
        sender.setDefaultEncoding("UTF-8");
        sender.setHost("smtp.263.net");
        sender.setProtocol("smtp");
        sender.setUsername("op_service@bjyada.com");
        sender.setPassword("eposp1");

        MimeMessage me = sender.createMimeMessage();
        MimeMessageHelper h = new MimeMessageHelper(me, true);
        h.setFrom(Objects.requireNonNull(sender.getUsername()));

        h.setTo("xinhui.zhang@bjyada.com");
        h.setSubject("测试换行");
        h.setText("第一行<br>第二行",true);//这里加了个参数 true

        sender.send(me);

    }
```



## 英语

References 引用

proxy 代理

Configuration 配置

## 主开发人员负责的事情

### 前期

1. 看文档
2. 建分支
3. wss分任务
4. git分权限
5. 任务计划（除特殊情况，计划不往后延）
6. 加密机能否使用



### 文档

流程图和服务需要流程图

写readme或者doc文档



### 每日工作

问进度